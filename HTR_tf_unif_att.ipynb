{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTR_tf_unif_att.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hramchenko/Handwritting/blob/master/HTR_tf_unif_att.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uL5QRz_WMkMF",
        "colab_type": "code",
        "outputId": "e57c9aab-62ad-4bc3-de2a-33a5710703ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Device \" + torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\")\n",
        "#device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device Tesla K80\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5M_rV-VMqso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVeBVZEgMtb2",
        "colab_type": "code",
        "outputId": "764c1053-ed99-4b27-8e23-575f150ba5fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./Handwritting/\")\n",
        "from IAMWords import IAMWords\n",
        "train_set = IAMWords(\"train\", \"./IAM/\", batch_size=batch_size)\n",
        "test_set = IAMWords(\"test\", \"./IAM/\", batch_size=batch_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading ./IAM/words.train.pkl...\n",
            "Reading finished\n",
            "Reading ./IAM/words.test.pkl...\n",
            "Reading finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SiZq2SoAI3yt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def modify_dataset(dataset):\n",
        "  l = len(dataset.codes)\n",
        "  s = \"<START>\"\n",
        "  dataset.codes[s] = l\n",
        "  dataset.inv_codes[l] = s\n",
        "  return dataset\n",
        "\n",
        "train_set = modify_dataset(train_set)\n",
        "test_set = modify_dataset(test_set)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2fWx6tuK-4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.core.debugger import set_trace\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLNlm1yURr4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, size, padding=1, pool_layer=nn.MaxPool2d(2, stride=2),\n",
        "                 bn=False, dropout=False, activation_fn=nn.ReLU(), stride=1):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(size[0], size[1], size[2], padding=padding, stride=stride))\n",
        "        if pool_layer is not None:\n",
        "            layers.append(pool_layer)\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(size[1]))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout2d())\n",
        "        layers.append(activation_fn)\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XmHNGG3oRshP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeconvLayer(nn.Module):\n",
        "    def __init__(self, size, padding=1, stride=1, \n",
        "                 bn=False, dropout=False, activation_fn=nn.ReLU(), output_padding=0):\n",
        "        super(DeconvLayer, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.ConvTranspose2d(size[0], size[1], size[2], padding=padding, \n",
        "                                         stride=stride, output_padding=output_padding))\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(size[1]))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout2d())\n",
        "        layers.append(activation_fn)\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hO1gydZeRvE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self, sizes, dropout=False, activation_fn=nn.Tanh):\n",
        "        super(FullyConnected, self).__init__()\n",
        "        layers = []\n",
        "        \n",
        "        for i in range(len(sizes) - 2):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if dropout:\n",
        "                layers.append(nn.Dropout())\n",
        "            layers.append(activation_fn())\n",
        "        else: # нам не нужен дропаут и фнкция активации в последнем слое\n",
        "            layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QuAkNIOOQkar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FullyConnectedX(nn.Module):\n",
        "    def __init__(self, sizes, dropout=False, activation_fn=nn.Tanh(), flatten=False, last_fn=None):\n",
        "        super(FullyConnectedX, self).__init__()\n",
        "        layers = []\n",
        "        self.flatten = flatten\n",
        "        for i in range(len(sizes) - 2):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if dropout:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            layers.append(activation_fn) # нам не нужен дропаут и фнкция активации в последнем слое\n",
        "        else: \n",
        "            layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
        "        if last_fn is not None:\n",
        "            layers.append(last_fn)\n",
        "        self.model = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.flatten:\n",
        "            x = x.view(x.shape[0], -1)\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tNCy7E6BNI1t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = train_set.make_batch()\n",
        "data, target = batch\n",
        "target = target.to(device)\n",
        "data = data/255.0\n",
        "data = data.view(batch_size, 1, 128, 400).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_P9OQHd-uOoE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HTREncoder(nn.Module):\n",
        "    def __init__(self, batchnorm=True, dropout=False):\n",
        "        super(HTREncoder, self).__init__()\n",
        "        \n",
        "        self.convolutions = nn.Sequential(\n",
        "        ConvLayer([1, 16, 3], padding=0, bn=batchnorm),\n",
        "        ConvLayer([16, 32, 3], padding=0, bn=batchnorm),\n",
        "        #ConvLayer([32, 50, 3], padding=0, bn=batchnorm),\n",
        "        ConvLayer([32, 64, 3], padding=0, stride=2, bn=batchnorm, pool_layer=None))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.convolutions(x)\n",
        "        h = F.max_pool2d(h, [h.size(2), 1], padding=[0, 0])\n",
        "        h = h.permute([2, 3, 0, 1])[0]\n",
        "        return h\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihilbywpul9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = HTREncoder().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cXja4G8p7KKz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_onehot(x, n):\n",
        "    one_hot = torch.zeros((x.shape[0], n)).to(device)\n",
        "    one_hot.scatter_(1, x[:, None], 1.)\n",
        "    if device is not None:\n",
        "        one_hot = one_hot.to(device)\n",
        "    return one_hot  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIiy-eFLvC5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HTRDecoder(nn.Module):\n",
        "    def __init__(self, ntoken, encoded_width=48, encoded_height=64, batchnorm=True, dropout=False, rnn_type=\"LSTM\"):\n",
        "        super(HTRDecoder, self).__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.encoded_height = encoded_height\n",
        "        self.lstm_size = 256\n",
        "        lstm_layers = 1\n",
        "        self.rnn_type = rnn_type\n",
        "        \n",
        "        if rnn_type == \"LSTM\":\n",
        "          self.rnn = nn.LSTM(self.encoded_height*encoded_width + ntoken, self.lstm_size, lstm_layers, dropout=0.3, bidirectional=False)\n",
        "        else:\n",
        "          self.rnn = nn.GRU(self.encoded_height*encoded_width + ntoken, self.lstm_size, lstm_layers, dropout=0.3, bidirectional=False)\n",
        "        self.embedding = nn.Embedding(ntoken, ntoken)\n",
        "        self.decoder = nn.Linear(1*self.lstm_size*1, ntoken)#*batch_size)\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        self.attention = FullyConnectedX([self.lstm_size + self.encoded_height*encoded_width, self.encoded_height*encoded_width*2,  self.encoded_height*encoded_width], activation_fn=nn.LeakyReLU(0.2), last_fn=nn.Tanh())\n",
        "        #self.concatenated = torch.FloatTensor(24, )\n",
        "    \n",
        "    def forward(self, x, prev, hidden=None):\n",
        "        #set_trace()\n",
        "        x = self.drop(x)\n",
        "        if hidden is not None:\n",
        "          #print(x.shape)\n",
        "          #print(hidden.shape)\n",
        "          attention_inp = torch.cat([x, hidden], dim=2)\n",
        "          #print(attention_inp.shape)\n",
        "          attention_w = self.attention(attention_inp)\n",
        "          attention_w = F.softmax(self.attention(attention_inp), dim=1)\n",
        "          #print(attention_w.shape)\n",
        "          #print(x.shape)\n",
        "          x = x * attention_w\n",
        "          #print(\"********************\")\n",
        "          #print(x)\n",
        "          #print(attention_w)\n",
        "          #print(X)\n",
        "          #print(\"---------------\")\n",
        "        #emb = self.embedding(prev)\n",
        "        emb = to_onehot(prev.squeeze(), self.ntoken)\n",
        "        emb = emb.unsqueeze(1)\n",
        "        #print(emb.shape)\n",
        "        emb = emb.permute([1, 0, 2])\n",
        "        x = torch.cat([x, emb], dim=2)\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.drop(x)\n",
        "        x = self.decoder(x)\n",
        "        return x, hidden  \n",
        "      \n",
        "    def makeHidden(self):\n",
        "      if self.rnn_type == \"LSTM\":\n",
        "        h1 = torch.zeros(1, batch_size, self.lstm_size).to(device)\n",
        "        h2 = torch.zeros(1, batch_size, self.lstm_size).to(device)\n",
        "        return (h1, h2)\n",
        "      else:\n",
        "        h1 = torch.zeros(1, batch_size, self.lstm_size).to(device)\n",
        "        return h1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "coyZNSEbv6CS",
        "colab_type": "code",
        "outputId": "72dfc10c-840d-41fa-bc35-bee2509570cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "decoder = HTRDecoder(len(train_set.codes), rnn_type=\"GRU\").to(device)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ziLheucQKlpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "START = train_set.codes['<START>']\n",
        "current_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "current_symbol[:, :] = START"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GHhQNaOtyJA",
        "colab_type": "code",
        "outputId": "30a7ed62-2e3d-417d-f85d-2a2c09b3a6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "23*64\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "JUtlRV5GxNpu",
        "colab_type": "code",
        "outputId": "bbcefc02-73bd-485c-eccb-a428fda3281c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16011
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "from random import random\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "  print(\"Training epoch \" + str(epoch) + \"...\")\n",
        "  train_set.to_start()\n",
        "  batch_idx = 0\n",
        "  c_loss = 0\n",
        "  START = train_set.codes['<START>']\n",
        "  current_symbol = torch.LongTensor(batch_size, 30+1).to(device)\n",
        "  while True:\n",
        "    batch = train_set.make_batch()\n",
        "    if batch is None:\n",
        "      break\n",
        "    encoder.zero_grad()\n",
        "    decoder.zero_grad()\n",
        "    \n",
        "    data, target = batch\n",
        "    data = data.view(batch_size, 1, 128, 400)/255.0\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    hidden = decoder.makeHidden()    \n",
        "\n",
        "    loss = 0\n",
        "    enc = encoder(data)\n",
        "    #print(enc.shape)\n",
        "    #s = enc.contiguous().view(1, batch_size, -1)\n",
        "   \n",
        "    s = enc.permute(1, 0, 2)\n",
        "    s = s.flatten(start_dim=1).view(1, 30, -1)\n",
        "    \n",
        "    current_symbol[:, 0] = START\n",
        "    use_teacher_forcing = True if random() < teacher_forcing_ratio else False\n",
        "    #print(\"*************\")\n",
        "    for i in range(0, target.shape[1]):\n",
        "      symb = current_symbol[:, i].view(batch_size, 1).contiguous()\n",
        "      dec, hidden = decoder(s, symb, hidden)\n",
        "      if use_teacher_forcing:\n",
        "        current_symbol[:, i + 1] = target[:, i]\n",
        "      else:\n",
        "        sampled = torch.multinomial(dec.exp(), 1)\n",
        "        current_symbol[:, i+1] = sampled.squeeze()\n",
        "      #print(dec.shape)\n",
        "      o = dec#dec.view(30, 1, 81).flatten(start_dim=0,end_dim=1)\n",
        "      #print(o.shape)\n",
        "      t = target[:, i].flatten()\n",
        "      loss += criterion(o, t)\n",
        "      #print(t[0].shape)\n",
        "#      print(\"->\" + train_set.inv_codes[t[0].item()])\n",
        "#      print(train_set.inv_codes[o[0]] + \"->\" + train_set.inv_codes[t[0]])\n",
        "    c_loss += loss.item()\n",
        "    freq = 10\n",
        "    if (batch_idx % freq == 0) and (batch_idx != 0):\n",
        "      print(\"TF: \" + str(use_teacher_forcing))\n",
        "      if not use_teacher_forcing:\n",
        "        for k in range(0, 5):\n",
        "           print(\"  \" + train_set.decode_word(target[k,:]) + \" -> \" + train_set.decode_word(current_symbol[k,:]))\n",
        "      c_loss /= freq \n",
        "      print(\"  Batch: \" + str(batch_idx) + \" Loss: \" + str(c_loss))\n",
        "      c_loss = 0\n",
        "      \n",
        "\n",
        "      \n",
        "    loss.backward()\n",
        "    grad_clip = 0.1\n",
        "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), grad_clip)\n",
        "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), grad_clip)\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    batch_idx += 1\n",
        "\n",
        "for i in range(0, 100):\n",
        "  train(i)\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0...\n",
            "TF: False\n",
            "  the                            -> <START>J-xX3t<START>Ie4<START>kIW7cdmuj)SBYv.EFJ\n",
            "  outlawed                       -> <START> p<START>k09F) 3( p;QZ4_ldO - El kb\n",
            "  707                            -> <START>*k)T?6vmDo-:38mC*b?H3\"Dd0Q04Y\n",
            "  census                         -> <START>hXH0?;-w 1\"?SfSdWUBw/YE.FfSJE\n",
            "  win                            -> <START>qQ:2:t+1 PE87mCee5<START>G?)<START>Km0wQ0\n",
            "  Batch: 10 Loss: 125.26309204101562\n",
            "TF: True\n",
            "  Batch: 20 Loss: 86.98272399902343\n",
            "TF: False\n",
            "  or                             -> <START>2 r &Z  l 6   J;; .e?Xt+<START> R  \n",
            "  had                            -> <START>YmO8tPrKu4( L  acbkt & / w # \n",
            "  the                            -> <START>'mY)<START>0DjH mCAGx'2X   Jej.E: O\n",
            "  ,                              -> <START>)Zyz fEwEh rV Ha#Yu0/'9xg 5nu\n",
            "  .                              -> <START>J9F45<START>J!bzwVY+1GCg dh_T+72A0 \n",
            "  Batch: 30 Loss: 65.50655708312988\n",
            "TF: False\n",
            "  out                            -> <START> ;h  sQ2+4L  YT   ' _y ?  6: \n",
            "  middle-aged                    -> <START>7G,     /M    U)        <START>    \n",
            "  brought                        -> <START>G( U o                       \n",
            "  courageous                     -> <START>Z   1T1      A       N  t   e\n",
            "  of                             -> <START>E.U  )  M   o8  M.;is   a  JQ\n",
            "  Batch: 40 Loss: 46.09463348388672\n",
            "TF: True\n",
            "  Batch: 50 Loss: 28.931697654724122\n",
            "TF: False\n",
            "  of                             -> <START>fug                          \n",
            "  .                              -> <START>B: Om              .   s y   \n",
            "  .                              -> <START>q '  *\"                      \n",
            "  had                            -> <START>FqE  e                       \n",
            "  come                           -> <START>E 1      g                   \n",
            "  Batch: 60 Loss: 23.400713157653808\n",
            "TF: True\n",
            "  Batch: 70 Loss: 19.771328926086426\n",
            "TF: True\n",
            "  Batch: 80 Loss: 18.292368030548097\n",
            "TF: False\n",
            "  Northern                       -> <START>\"?07ee.i D    l              \n",
            "  and                            -> <START>Co;                          \n",
            "  her                            -> <START>t s                          \n",
            "  At                             -> <START>p s                          \n",
            "  ,                              -> <START>k                            \n",
            "  Batch: 90 Loss: 17.564652347564696\n",
            "TF: False\n",
            "  was                            -> <START>4t                           \n",
            "  is                             -> <START>6 e                          \n",
            "  '                              -> <START>O j                          \n",
            "  Malachias                      -> <START>3 # e wm    v                \n",
            "  waste                          -> <START>0SH h e                      \n",
            "  Batch: 100 Loss: 16.439141845703126\n",
            "TF: True\n",
            "  Batch: 110 Loss: 17.790457344055177\n",
            "TF: True\n",
            "  Batch: 120 Loss: 17.683660316467286\n",
            "TF: True\n",
            "  Batch: 130 Loss: 17.128349685668944\n",
            "TF: False\n",
            "  I                              -> <START>9'ei i                       \n",
            "  and                            -> <START>h e?                         \n",
            "  vividly                        -> <START>aFr#ev e                     \n",
            "  will                           -> <START>;hD c                        \n",
            "  were                           -> <START>1m e e e                     \n",
            "  Batch: 140 Loss: 16.099253749847414\n",
            "TF: True\n",
            "  Batch: 150 Loss: 15.869893741607665\n",
            "TF: True\n",
            "  Batch: 160 Loss: 15.96667947769165\n",
            "TF: True\n",
            "  Batch: 170 Loss: 15.930722713470459\n",
            "TF: False\n",
            "  change                         -> <START><START>buntse    a                 \n",
            "  '                              -> <START>9R                           \n",
            "  ebriety                        -> <START>rawaansw  s                  \n",
            "  to                             -> <START>tn Q                         \n",
            "  direction                      -> <START>Wistn                        \n",
            "  Batch: 180 Loss: 15.448867130279542\n",
            "TF: False\n",
            "  people                         -> <START>hfeariolesrt      h          \n",
            "  .                              -> <START>                             \n",
            "  from                           -> <START>nuee y                       \n",
            "  programme                      -> <START>yrhlofsvsaum  n       h      \n",
            "  ,                              -> <START>S'n                          \n",
            "  Batch: 190 Loss: 16.033609008789064\n",
            "TF: True\n",
            "  Batch: 200 Loss: 16.127076435089112\n",
            "TF: False\n",
            "  engaged                        -> <START>icdiee                       \n",
            "  that                           -> <START>1*fa                         \n",
            "  was                            -> <START>io                           \n",
            "  that                           -> <START>bv                           \n",
            "  President                      -> <START>tr Qa                        \n",
            "  Batch: 210 Loss: 15.132635593414307\n",
            "TF: True\n",
            "  Batch: 220 Loss: 15.135289001464844\n",
            "TF: True\n",
            "  Batch: 230 Loss: 15.235044765472413\n",
            "TF: True\n",
            "  Batch: 240 Loss: 14.199327182769775\n",
            "TF: True\n",
            "  Batch: 250 Loss: 15.520992660522461\n",
            "TF: True\n",
            "  Batch: 260 Loss: 14.225655841827393\n",
            "TF: False\n",
            "  feelings                       -> <START>shgals                       \n",
            "  the                            -> <START>o                            \n",
            "  the                            -> <START>ea                           \n",
            "  train                          -> <START>tntt                         \n",
            "  me                             -> <START>1o                           \n",
            "  Batch: 270 Loss: 14.933650493621826\n",
            "TF: False\n",
            "  -                              -> <START>rx                           \n",
            "  As                             -> <START>m1                           \n",
            "  to                             -> <START>fven                         \n",
            "  3,000                          -> <START>rthiia                       \n",
            "  of                             -> <START>ho                           \n",
            "  Batch: 280 Loss: 14.757081127166748\n",
            "TF: True\n",
            "  Batch: 290 Loss: 13.931443214416504\n",
            "TF: True\n",
            "  Batch: 300 Loss: 15.494112873077393\n",
            "TF: False\n",
            "  to                             -> <START>yh                           \n",
            "  tools                          -> <START>vha                          \n",
            "  heartily                       -> <START>htise ie                     \n",
            "  to                             -> <START>My                           \n",
            "  swim                           -> <START>cvagwa                       \n",
            "  Batch: 310 Loss: 14.241479396820068\n",
            "TF: False\n",
            "  ,                              -> <START>i                            \n",
            "  're                            -> <START>ot                           \n",
            "  his                            -> <START>.v                           \n",
            "  observe                        -> <START>mysvavr e                    \n",
            "  ,                              -> <START>b                            \n",
            "  Batch: 320 Loss: 15.27077226638794\n",
            "TF: False\n",
            "  faces                          -> <START>Mohthi                       \n",
            "  mortgage                       -> <START>Lscl hr                      \n",
            "  .                              -> <START> t                           \n",
            "  stomach-ulcers                 -> <START>hohigsglni                   \n",
            "  electrically                   -> <START>-eyr tcr                     \n",
            "  Batch: 330 Loss: 15.564503002166749\n",
            "TF: True\n",
            "  Batch: 340 Loss: 13.876486682891846\n",
            "TF: False\n",
            "  ready                          -> <START>dritt                        \n",
            "  be                             -> <START>ait                          \n",
            "  an                             -> <START>ti       s                   \n",
            "  newly-wed                      -> <START>estendiet                    \n",
            "  our                            -> <START>Cp t                         \n",
            "  Batch: 350 Loss: 13.501619625091553\n",
            "TF: True\n",
            "  Batch: 360 Loss: 15.564505195617675\n",
            "TF: True\n",
            "  Batch: 370 Loss: 14.60189094543457\n",
            "TF: True\n",
            "  Batch: 380 Loss: 15.604116630554199\n",
            "TF: True\n",
            "  Batch: 390 Loss: 15.005278205871582\n",
            "TF: True\n",
            "  Batch: 400 Loss: 13.178246593475341\n",
            "TF: True\n",
            "  Batch: 410 Loss: 14.615343570709229\n",
            "TF: False\n",
            "  .                              -> <START>yr                           \n",
            "  -                              -> <START>o                            \n",
            "  room                           -> <START>ugyrl                        \n",
            "  the                            -> <START>inee                         \n",
            "  statement                      -> <START>poanmrti tzrd                \n",
            "  Batch: 420 Loss: 14.770469570159912\n",
            "TF: True\n",
            "  Batch: 430 Loss: 14.237414741516114\n",
            "TF: True\n",
            "  Batch: 440 Loss: 15.261521053314208\n",
            "TF: True\n",
            "  Batch: 450 Loss: 13.91619234085083\n",
            "TF: False\n",
            "  pleaded                        -> <START>hteco tg                     \n",
            "  .                              -> <START>.                            \n",
            "  medicine                       -> <START>tcvonessi                    \n",
            "  with                           -> <START>hNo                          \n",
            "  Social                         -> <START>-iedro                       \n",
            "  Batch: 460 Loss: 14.571836853027344\n",
            "TF: True\n",
            "  Batch: 470 Loss: 13.340085124969482\n",
            "TF: True\n",
            "  Batch: 480 Loss: 13.662092018127442\n",
            "TF: True\n",
            "  Batch: 490 Loss: 15.062032318115234\n",
            "TF: True\n",
            "  Batch: 500 Loss: 13.740860939025879\n",
            "TF: False\n",
            "  be                             -> <START>hil                          \n",
            "  law                            -> <START>eeivt                        \n",
            "  high                           -> <START>-ag\"                         \n",
            "  greater                        -> <START>jse-lso                      \n",
            "  for                            -> <START>hho                          \n",
            "  Batch: 510 Loss: 13.801226139068604\n",
            "TF: True\n",
            "  Batch: 520 Loss: 14.03649673461914\n",
            "TF: False\n",
            "  of                             -> <START>abh                          \n",
            "  I                              -> <START>e                            \n",
            "  of                             -> <START>fg                           \n",
            "  side                           -> <START>att                          \n",
            "  felt                           -> <START>pwre                         \n",
            "  Batch: 530 Loss: 13.74963960647583\n",
            "TF: True\n",
            "  Batch: 540 Loss: 13.325744724273681\n",
            "TF: True\n",
            "  Batch: 550 Loss: 14.965508937835693\n",
            "TF: True\n",
            "  Batch: 560 Loss: 13.83756513595581\n",
            "TF: True\n",
            "  Batch: 570 Loss: 13.09440574645996\n",
            "TF: False\n",
            "  room                           -> <START>IQeai                        \n",
            "  1961                           -> <START>ndn                          \n",
            "  .                              -> <START>.                            \n",
            "  gratify                        -> <START>opnansd                      \n",
            "  Adhem                          -> <START>buececslm                    \n",
            "  Batch: 580 Loss: 14.600847244262695\n",
            "TF: False\n",
            "  The                            -> <START>.he                          \n",
            "  the                            -> <START>acPe                         \n",
            "  few                            -> <START>dCslt                        \n",
            "  ,                              -> <START>                             \n",
            "  from                           -> <START>waeo                         \n",
            "  Batch: 590 Loss: 12.9480637550354\n",
            "TF: False\n",
            "  their                          -> <START>obola t  s                   \n",
            "  gross                          -> <START>ne n                         \n",
            "  them                           -> <START>tDari                        \n",
            "  staff                          -> <START>nwme                         \n",
            "  you                            -> <START>ta                           \n",
            "  Batch: 600 Loss: 13.582419681549073\n",
            "TF: True\n",
            "  Batch: 610 Loss: 12.893364334106446\n",
            "TF: False\n",
            "  the                            -> <START>ft                           \n",
            "  thirst                         -> <START>vlteat                       \n",
            "  '                              -> <START>s                            \n",
            "  years                          -> <START>D eo                         \n",
            "  finger                         -> <START>userf                        \n",
            "  Batch: 620 Loss: 14.751359844207764\n",
            "TF: False\n",
            "  its                            -> <START>-Led                         \n",
            "  month                          -> <START>otriee                       \n",
            "  .                              -> <START>a                            \n",
            "  always                         -> <START>wtounsd                      \n",
            "  I                              -> <START>ls                           \n",
            "  Batch: 630 Loss: 13.508672332763672\n",
            "TF: True\n",
            "  Batch: 640 Loss: 14.043551445007324\n",
            "TF: False\n",
            "  ,                              -> <START>e                            \n",
            "  into                           -> <START>rnee                         \n",
            "  .                              -> <START>                             \n",
            "  health                         -> <START>-els                         \n",
            "  as                             -> <START>ce                           \n",
            "  Batch: 650 Loss: 14.119449424743653\n",
            "TF: True\n",
            "  Batch: 660 Loss: 13.824234199523925\n",
            "TF: True\n",
            "  Batch: 670 Loss: 13.124685478210449\n",
            "TF: True\n",
            "  Batch: 680 Loss: 13.975512886047364\n",
            "TF: True\n",
            "  Batch: 690 Loss: 13.94758768081665\n",
            "TF: False\n",
            "  the                            -> <START>a/r                          \n",
            "  and                            -> <START>orl                          \n",
            "  in                             -> <START>c g                          \n",
            "  rose-brocade                   -> <START>eahaeayinnse                 \n",
            "  pitch                          -> <START>ko                           \n",
            "  Batch: 700 Loss: 14.364490985870361\n",
            "TF: False\n",
            "  followed                       -> <START>warhagse                     \n",
            "  in                             -> <START>l l                          \n",
            "  attached                       -> <START>mauees                       \n",
            "  more                           -> <START>ar!en                        \n",
            "  She                            -> <START>rsk                          \n",
            "  Batch: 710 Loss: 13.766291904449464\n",
            "TF: True\n",
            "  Batch: 720 Loss: 14.326039123535157\n",
            "TF: False\n",
            "  ,                              -> <START>j.                           \n",
            "  grinder                        -> <START>andern                       \n",
            "  must                           -> <START>LPubg                        \n",
            "  public                         -> <START>heaenr                       \n",
            "  foreigners                     -> <START>thhdar ug                    \n",
            "  Batch: 730 Loss: 13.254283142089843\n",
            "TF: False\n",
            "  were                           -> <START>iille                        \n",
            "  were                           -> <START>Eier                         \n",
            "  is                             -> <START>Bt                           \n",
            "  would                          -> <START>heosrl                       \n",
            "  \"                              -> <START>,                            \n",
            "  Batch: 740 Loss: 13.654958248138428\n",
            "TF: False\n",
            "  slightly                       -> <START>*orv                         \n",
            "  conference                     -> <START>Lsroedg                      \n",
            "  a                              -> <START>-s                           \n",
            "  guilds                         -> <START>bwnnel                       \n",
            "  !                              -> <START>,                            \n",
            "  Batch: 750 Loss: 14.047063159942628\n",
            "TF: True\n",
            "  Batch: 760 Loss: 14.107427883148194\n",
            "TF: False\n",
            "  .                              -> <START>b                            \n",
            "  against                        -> <START>feiiir                       \n",
            "  tough                          -> <START>ppuethe                      \n",
            "  ghastly                        -> <START>kaot                         \n",
            "  House                          -> <START>usirr                        \n",
            "  Batch: 770 Loss: 13.334339904785157\n",
            "TF: True\n",
            "  Batch: 780 Loss: 14.206512641906738\n",
            "TF: False\n",
            "  his                            -> <START>dw                           \n",
            "  I                              -> <START>g                            \n",
            "  is                             -> <START>brw                          \n",
            "  And                            -> <START>aeft                         \n",
            "  .                              -> <START>s                            \n",
            "  Batch: 790 Loss: 14.342885303497315\n",
            "TF: False\n",
            "  sea                            -> <START>a)g                          \n",
            "  mind                           -> <START>Pos                          \n",
            "  and                            -> <START>fae                          \n",
            "  .                              -> <START>.                            \n",
            "  said                           -> <START>tthas                        \n",
            "  Batch: 800 Loss: 14.02397804260254\n",
            "TF: False\n",
            "  minor                          -> <START>iechMs                       \n",
            "  cosmic                         -> <START>ntHnn                        \n",
            "  a                              -> <START>r                            \n",
            "  soon                           -> <START>oaht                         \n",
            "  co-operation                   -> <START>Lmeiuurrs                    \n",
            "  Batch: 810 Loss: 14.36694107055664\n",
            "TF: True\n",
            "  Batch: 820 Loss: 14.244781303405762\n",
            "TF: False\n",
            "  most                           -> <START>rrgnd                        \n",
            "  into                           -> <START>o0 o                         \n",
            "  a                              -> <START>k f                          \n",
            "  also                           -> <START>ten                          \n",
            "  dead                           -> <START>nss                          \n",
            "  Batch: 830 Loss: 13.64411792755127\n",
            "TF: False\n",
            "  is                             -> <START>e                            \n",
            "  the                            -> <START>fft                          \n",
            "  a                              -> <START>6                            \n",
            "  assured                        -> <START>sihgfitsco                   \n",
            "  ,                              -> <START>,                            \n",
            "  Batch: 840 Loss: 13.781307983398438\n",
            "TF: True\n",
            "  Batch: 850 Loss: 14.301806831359864\n",
            "TF: True\n",
            "  Batch: 860 Loss: 13.846383380889893\n",
            "TF: False\n",
            "  very                           -> <START>ssw d                        \n",
            "  everyone                       -> <START>freaetsd                     \n",
            "  ,                              -> <START>&                            \n",
            "  the                            -> <START>ait                          \n",
            "  war                            -> <START>hah                          \n",
            "  Batch: 870 Loss: 14.692004108428955\n",
            "TF: True\n",
            "  Batch: 880 Loss: 14.267558383941651\n",
            "TF: True\n",
            "  Batch: 890 Loss: 13.418957424163818\n",
            "TF: True\n",
            "  Batch: 900 Loss: 13.197203731536865\n",
            "TF: False\n",
            "  proved                         -> <START>ostvn                        \n",
            "  which                          -> <START>uatwl                        \n",
            "  delicacy                       -> <START>eaupgtl a                    \n",
            "  and                            -> <START>9prnh                        \n",
            "  the                            -> <START>ybte                         \n",
            "  Batch: 910 Loss: 13.775721168518066\n",
            "TF: True\n",
            "  Batch: 920 Loss: 12.778517246246338\n",
            "TF: True\n",
            "  Batch: 930 Loss: 13.445189952850342\n",
            "TF: True\n",
            "  Batch: 940 Loss: 13.914069175720215\n",
            "TF: True\n",
            "  Batch: 950 Loss: 13.61466646194458\n",
            "TF: False\n",
            "  \"                              -> <START>                             \n",
            "  to                             -> <START>eo                           \n",
            "  over                           -> <START>hai                          \n",
            "  throw                          -> <START>mohee                        \n",
            "  what                           -> <START>eauref                       \n",
            "  Batch: 960 Loss: 14.0306471824646\n",
            "TF: False\n",
            "  Order                          -> <START>sion                         \n",
            "  much                           -> <START>ulyo                         \n",
            "  his                            -> <START>onnd                         \n",
            "  of                             -> <START>lt                           \n",
            "  do                             -> <START>Gt                           \n",
            "  Batch: 970 Loss: 13.491103172302246\n",
            "TF: True\n",
            "  Batch: 980 Loss: 13.913479804992676\n",
            "TF: False\n",
            "  me                             -> <START>haa                          \n",
            "  there                          -> <START>eardn                        \n",
            "  \"                              -> <START>o                            \n",
            "  whom                           -> <START>weelal                       \n",
            "  shabby                         -> <START>Hpelse                       \n",
            "  Batch: 990 Loss: 13.778684711456298\n",
            "TF: False\n",
            "  stepped                        -> <START>wtsot                        \n",
            "  startled                       -> <START>feuahel                      \n",
            "  to                             -> <START>Tu                           \n",
            "  he                             -> <START>abes                         \n",
            "  children                       -> <START>aidaae t                     \n",
            "  Batch: 1000 Loss: 14.23856325149536\n",
            "TF: False\n",
            "  insensitively                  -> <START>acmnvyotps                   \n",
            "  maker                          -> <START>foueo                        \n",
            "  vigour                         -> <START>phhrtr                       \n",
            "  him                            -> <START>ult                          \n",
            "  WHICH                          -> <START>_haan e      t               \n",
            "  Batch: 1010 Loss: 13.644436454772949\n",
            "TF: True\n",
            "  Batch: 1020 Loss: 14.33761281967163\n",
            "TF: True\n",
            "  Batch: 1030 Loss: 15.436759567260742\n",
            "TF: True\n",
            "  Batch: 1040 Loss: 13.183752536773682\n",
            "TF: True\n",
            "  Batch: 1050 Loss: 13.122447299957276\n",
            "TF: True\n",
            "  Batch: 1060 Loss: 13.483058071136474\n",
            "TF: False\n",
            "  of                             -> <START>to                           \n",
            "  is                             -> <START>s                            \n",
            "  they                           -> <START>raoo                         \n",
            "  is                             -> <START>d                            \n",
            "  go                             -> <START>hrt                          \n",
            "  Batch: 1070 Loss: 14.132068634033203\n",
            "TF: True\n",
            "  Batch: 1080 Loss: 13.232865715026856\n",
            "TF: True\n",
            "  Batch: 1090 Loss: 12.94987621307373\n",
            "TF: False\n",
            "  here                           -> <START>amd o                        \n",
            "  .                              -> <START>                             \n",
            "  want                           -> <START>Troee                        \n",
            "  had                            -> <START>rix                          \n",
            "  lace                           -> <START>oei                          \n",
            "  Batch: 1100 Loss: 13.760678386688232\n",
            "TF: True\n",
            "  Batch: 1110 Loss: 14.06956615447998\n",
            "TF: True\n",
            "  Batch: 1120 Loss: 12.841732692718505\n",
            "TF: False\n",
            "  Watkinson                      -> <START>lu2gapicte                   \n",
            "  The                            -> <START>Nim                          \n",
            "  from                           -> <START>Pohrl                        \n",
            "  be                             -> <START>hI                           \n",
            "  divisions                      -> <START>ourcrowind                   \n",
            "  Batch: 1130 Loss: 13.547529029846192\n",
            "TF: False\n",
            "  or                             -> <START>rd                           \n",
            "  which                          -> <START>yenlmh                       \n",
            "  .                              -> <START>,                            \n",
            "  \"                              -> <START>                             \n",
            "  dairy                          -> <START>wudhea                       \n",
            "  Batch: 1140 Loss: 13.886973476409912\n",
            "TF: True\n",
            "  Batch: 1150 Loss: 12.88062744140625\n",
            "TF: True\n",
            "  Batch: 1160 Loss: 13.109292697906493\n",
            "TF: False\n",
            "  formidable                     -> <START>Ctomeltieslr                 \n",
            "  this                           -> <START>eare                         \n",
            "  can                            -> <START>hee                          \n",
            "  ,                              -> <START>y                            \n",
            "  eye                            -> <START>vet                          \n",
            "  Batch: 1170 Loss: 14.298961639404297\n",
            "TF: True\n",
            "  Batch: 1180 Loss: 13.443392086029053\n",
            "TF: False\n",
            "  even                           -> <START>ornet                        \n",
            "  control                        -> <START>Aocaed                       \n",
            "  .                              -> <START>,                            \n",
            "  and                            -> <START>weai                         \n",
            "  \"                              -> <START>i5.                          \n",
            "  Batch: 1190 Loss: 14.043793773651123\n",
            "TF: True\n",
            "  Batch: 1200 Loss: 14.328520107269288\n",
            "TF: False\n",
            "  .                              -> <START>,                            \n",
            "  ,                              -> <START>.                            \n",
            "  Constitution                   -> <START>cudfdmeram s                 \n",
            "  ,                              -> <START>,                            \n",
            "  save                           -> <START>ahe                          \n",
            "  Batch: 1210 Loss: 13.814335250854493\n",
            "TF: True\n",
            "  Batch: 1220 Loss: 12.984299659729004\n",
            "TF: True\n",
            "  Batch: 1230 Loss: 14.74093542098999\n",
            "TF: False\n",
            "  minds                          -> <START>Prlogt                       \n",
            "  .                              -> <START>\"                            \n",
            "  into                           -> <START>ohne                         \n",
            "  of                             -> <START>fde                          \n",
            "  ,                              -> <START>.e                           \n",
            "  Batch: 1240 Loss: 12.87743444442749\n",
            "TF: True\n",
            "  Batch: 1250 Loss: 13.729080104827881\n",
            "TF: False\n",
            "  had                            -> <START>poet                   l     \n",
            "  a                              -> <START>H                            \n",
            "  very                           -> <START>Sih                          \n",
            "  Giuseppe                       -> <START>uouree                       \n",
            "  he                             -> <START>ae                           \n",
            "  Batch: 1260 Loss: 13.949320697784424\n",
            "TF: False\n",
            "  Earl                           -> <START>;adpe                        \n",
            "  must                           -> <START>eahir s                      \n",
            "  Grinling                       -> <START>wspdmn t                     \n",
            "  that                           -> <START>tiln                         \n",
            "  's                             -> <START>,                            \n",
            "  Batch: 1270 Loss: 14.759399223327637\n",
            "TF: True\n",
            "  Batch: 1280 Loss: 14.956782627105714\n",
            "TF: True\n",
            "  Batch: 1290 Loss: 12.900738430023193\n",
            "TF: True\n",
            "  Batch: 1300 Loss: 13.298555183410645\n",
            "TF: False\n",
            "  The                            -> <START>w.                           \n",
            "  in                             -> <START>:g                           \n",
            "  made                           -> <START>cppcd                        \n",
            "  of                             -> <START>fo                           \n",
            "  ,                              -> <START>.                            \n",
            "  Batch: 1310 Loss: 13.074215316772461\n",
            "TF: False\n",
            "  Ponsonby                       -> <START>rriear                       \n",
            "  families                       -> <START>ounmm                        \n",
            "  Labour                         -> <START>aiyre i                      \n",
            "  which                          -> <START>twohde                       \n",
            "  very                           -> <START>hhe                          \n",
            "  Batch: 1320 Loss: 13.493202304840088\n",
            "TF: True\n",
            "  Batch: 1330 Loss: 12.905458927154541\n",
            "TF: False\n",
            "  first                          -> <START>iie                          \n",
            "  the                            -> <START>dos'                         \n",
            "  heard                          -> <START>al a                         \n",
            "  to                             -> <START>ft                           \n",
            "  abroad                         -> <START>hiilddo                      \n",
            "  Batch: 1340 Loss: 13.02708854675293\n",
            "TF: True\n",
            "  Batch: 1350 Loss: 13.111345195770264\n",
            "TF: False\n",
            "  if                             -> <START>d9f                          \n",
            "  duty                           -> <START>uept                         \n",
            "  they                           -> <START>dare                         \n",
            "  and                            -> <START>3ilh                         \n",
            "  the                            -> <START>)e                           \n",
            "  Batch: 1360 Loss: 12.55406675338745\n",
            "TF: False\n",
            "  crochet                        -> <START>sUpee s                      \n",
            "  moment                         -> <START>srOtnni g                    \n",
            "  voice                          -> <START>cnnul                        \n",
            "  superimposition                -> <START>tapSooirree tsn              \n",
            "  only                           -> <START>dael                         \n",
            "  Batch: 1370 Loss: 15.281833076477051\n",
            "TF: False\n",
            "  ,                              -> <START>l.                           \n",
            "  Lord                           -> <START>rcerl                        \n",
            "  .                              -> <START>n                            \n",
            "  a                              -> <START>ih                           \n",
            "  the                            -> <START>doe                          \n",
            "  Batch: 1380 Loss: 13.676794624328613\n",
            "TF: True\n",
            "  Batch: 1390 Loss: 12.315627574920654\n",
            "TF: False\n",
            "  .                              -> <START>.                            \n",
            "  the                            -> <START>ohe                          \n",
            "  I                              -> <START>to                           \n",
            "  February                       -> <START>khrntne                      \n",
            "  bloodstained                   -> <START>wWiepmdnlel   s              \n",
            "  Batch: 1400 Loss: 14.307814884185792\n",
            "TF: True\n",
            "  Batch: 1410 Loss: 13.20203971862793\n",
            "TF: False\n",
            "  does                           -> <START>.lsn                         \n",
            "  The                            -> <START>prh                          \n",
            "  of                             -> <START>fa                           \n",
            "  on                             -> <START>hol                          \n",
            "  had                            -> <START>b-ot                         \n",
            "  Batch: 1420 Loss: 12.519005393981933\n",
            "TF: False\n",
            "  bosses                         -> <START>tmc                          \n",
            "  of                             -> <START>St                           \n",
            "  ,                              -> <START>..                           \n",
            "  light                          -> <START>fie d                        \n",
            "  sea                            -> <START>Eff                          \n",
            "  Batch: 1430 Loss: 13.710680389404297\n",
            "TF: False\n",
            "  (                              -> <START>,                            \n",
            "  day-time                       -> <START>crfmtinne                    \n",
            "  is                             -> <START>ci                           \n",
            "  negotiations                   -> <START>dfaieilcteter                \n",
            "  point                          -> <START>Tfar                         \n",
            "  Batch: 1440 Loss: 13.385283088684082\n",
            "TF: False\n",
            "  easy                           -> <START>Seesm                        \n",
            "  Byron                          -> <START>ooitgt                       \n",
            "  Hell                           -> <START>hoee                         \n",
            "  discuss                        -> <START>Wdhltrag                     \n",
            "  why                            -> <START>baiek                        \n",
            "  Batch: 1450 Loss: 13.999961376190186\n",
            "TF: False\n",
            "  In                             -> <START>.                            \n",
            "  would                          -> <START>Fatai e                      \n",
            "  worrying                       -> <START>svitumllr                    \n",
            "  respectability                 -> <START>Aoircanvtss u                \n",
            "  gauge                          -> <START>bel                          \n",
            "  Batch: 1460 Loss: 14.12314682006836\n",
            "TF: False\n",
            "  diamonds                       -> <START>nrlraeisey t                 \n",
            "  say                            -> <START>,en                          \n",
            "  saw                            -> <START>wso                          \n",
            "  '                              -> <START>6e                           \n",
            "  been                           -> <START>bot                          \n",
            "  Batch: 1470 Loss: 13.66370096206665\n",
            "TF: False\n",
            "  with                           -> <START>wfeRe                        \n",
            "  the                            -> <START>aol                          \n",
            "  fragment                       -> <START>epeulenU                     \n",
            "  examine                        -> <START>utllii                       \n",
            "  )                              -> <START>,                            \n",
            "  Batch: 1480 Loss: 12.976618576049805\n",
            "TF: False\n",
            "  .                              -> <START>.                            \n",
            "  engine                         -> <START>aeeee n                      \n",
            "  worker                         -> <START>cioisygy                     \n",
            "  hideous                        -> <START>Aeolr                        \n",
            "  ,                              -> <START>,                            \n",
            "  Batch: 1490 Loss: 13.028197860717773\n",
            "TF: True\n",
            "  Batch: 1500 Loss: 13.682436561584472\n",
            "TF: False\n",
            "  necessary                      -> <START>faullhEnee                   \n",
            "  already                        -> <START>nurtd   y                    \n",
            "  of                             -> <START>os                           \n",
            "  soon                           -> <START>afe                          \n",
            "  parents                        -> <START>mevct                        \n",
            "  Batch: 1510 Loss: 14.327155876159669\n",
            "TF: False\n",
            "  .                              -> <START>,                            \n",
            "  Evadne                         -> <START>bcbleo                       \n",
            "  ones                           -> <START>tue                          \n",
            "  not                            -> <START>Cfhi                         \n",
            "  didn't                         -> <START>oaat                         \n",
            "  Batch: 1520 Loss: 13.255958747863769\n",
            "TF: True\n",
            "  Batch: 1530 Loss: 13.111885833740235\n",
            "TF: False\n",
            "  peoples                        -> <START>phmed                        \n",
            "  agreed                         -> <START>osmnur                       \n",
            "  to                             -> <START>n                            \n",
            "  unhesitatingly                 -> <START>tcasieioauso                 \n",
            "  sation                         -> <START>tipsb                        \n",
            "  Batch: 1540 Loss: 12.947468948364257\n",
            "TF: False\n",
            "  Dr.                            -> <START>fod                          \n",
            "  and                            -> <START>tehi                         \n",
            "  next                           -> <START>vdh                          \n",
            "  to                             -> <START>an                           \n",
            "  such                           -> <START>co r                         \n",
            "  Batch: 1550 Loss: 13.156795597076416\n",
            "TF: False\n",
            "  of                             -> <START>os                           \n",
            "  this                           -> <START>Moea                         \n",
            "  Monckton                       -> <START>uunurstg                     \n",
            "  advised                        -> <START>roveir e                     \n",
            "  There                          -> <START>;ua                          \n",
            "  Batch: 1560 Loss: 12.76469964981079\n",
            "TF: False\n",
            "  both                           -> <START>tsse                         \n",
            "  2eddicated                     -> <START>bEhongi                      \n",
            "  had                            -> <START>aeef                         \n",
            "  destructive                    -> <START>jraarddcs                    \n",
            "  things                         -> <START>ehns                         \n",
            "  Batch: 1570 Loss: 13.520585441589356\n",
            "TF: False\n",
            "  whom                           -> <START>matgyd                       \n",
            "  a                              -> <START>,                            \n",
            "  is                             -> <START>.                            \n",
            "  temperature                    -> <START>Eelrconaat                   \n",
            "  .                              -> <START>.                            \n",
            "  Batch: 1580 Loss: 12.882914638519287\n",
            "TF: True\n",
            "  Batch: 1590 Loss: 13.246910858154298\n",
            "TF: False\n",
            "  of                             -> <START>ie                           \n",
            "  as                             -> <START>5,                           \n",
            "  use                            -> <START>has                          \n",
            "  the                            -> <START>,1v                          \n",
            "  he                             -> <START>nss                          \n",
            "  Batch: 1600 Loss: 12.601131057739257\n",
            "TF: False\n",
            "  along                          -> <START>cuoae s                      \n",
            "  far                            -> <START>Go                           \n",
            "  He                             -> <START>se                           \n",
            "  .                              -> <START>,                            \n",
            "  under                          -> <START>hmhrar                       \n",
            "  Batch: 1610 Loss: 13.001175498962402\n",
            "TF: False\n",
            "  Joshua                         -> <START>arrern                       \n",
            "  to                             -> <START>to                           \n",
            "  going                          -> <START>jhc s                        \n",
            "  from                           -> <START>wety                         \n",
            "  United                         -> <START>ioopsdy   n                  \n",
            "  Batch: 1620 Loss: 13.438204860687256\n",
            "TF: False\n",
            "  said                           -> <START>honor                        \n",
            "  to                             -> <START>hrh                          \n",
            "  to                             -> <START>bm                           \n",
            "  number                         -> <START>caatcel n                    \n",
            "  of                             -> <START>io                           \n",
            "  Batch: 1630 Loss: 13.257971382141113\n",
            "TF: True\n",
            "  Batch: 1640 Loss: 12.423088264465331\n",
            "TF: True\n",
            "  Batch: 1650 Loss: 13.798373222351074\n",
            "TF: False\n",
            "  committed                      -> <START>cmoclcdtces                  \n",
            "  \"                              -> <START>h                            \n",
            "  seem                           -> <START>rotBs                        \n",
            "  made                           -> <START>dpbe  e                      \n",
            "  uses                           -> <START>Hag                          \n",
            "  Batch: 1660 Loss: 14.323843574523925\n",
            "TF: True\n",
            "  Batch: 1670 Loss: 13.099498176574707\n",
            "TF: False\n",
            "  presence                       -> <START>vnteine d                    \n",
            "  an                             -> <START>oa                           \n",
            "  this                           -> <START>tet                          \n",
            "  Play                           -> <START>arram                        \n",
            "  wasted                         -> <START>leicyre                      \n",
            "  Batch: 1680 Loss: 12.014258003234863\n",
            "TF: True\n",
            "  Batch: 1690 Loss: 13.383160305023193\n",
            "TF: True\n",
            "  Batch: 1700 Loss: 13.486000156402588\n",
            "TF: True\n",
            "  Batch: 1710 Loss: 13.017008590698243\n",
            "TF: False\n",
            "  his                            -> <START>hhn                          \n",
            "  glue                           -> <START>ihdd                         \n",
            "  's                             -> <START>Fn                           \n",
            "  he                             -> <START>rs                           \n",
            "  tie                            -> <START>io                           \n",
            "  Batch: 1720 Loss: 13.429090976715088\n",
            "TF: False\n",
            "  men                            -> <START>1is                          \n",
            "  taxi                           -> <START>lqira                        \n",
            "  had                            -> <START>ooi                          \n",
            "  and                            -> <START>Itr                          \n",
            "  case                           -> <START>P2                           \n",
            "  Batch: 1730 Loss: 13.372140884399414\n",
            "TF: True\n",
            "  Batch: 1740 Loss: 12.875575923919678\n",
            "TF: False\n",
            "  He                             -> <START>1a                           \n",
            "  himself                        -> <START>henta                        \n",
            "  ,                              -> <START>s                            \n",
            "  happens                        -> <START>mdnitine                     \n",
            "  diplomatist                    -> <START>saaarcg                      \n",
            "  Batch: 1750 Loss: 13.317202854156495\n",
            "TF: True\n",
            "  Batch: 1760 Loss: 13.416939163208008\n",
            "TF: False\n",
            "  Hebrew                         -> <START>kreeet                       \n",
            "  difference                     -> <START>k-epmnan                     \n",
            "  He                             -> <START>wo                           \n",
            "  actually                       -> <START>pceeeg                       \n",
            "  too                            -> <START>oaleg                        \n",
            "  Batch: 1770 Loss: 13.505088329315186\n",
            "TF: False\n",
            "  the                            -> <START>ind                          \n",
            "  Diana                          -> <START>eaaetb                       \n",
            "  ago                            -> <START>TlP                          \n",
            "  rest                           -> <START>tos                          \n",
            "  she                            -> <START>Bon                          \n",
            "  Batch: 1780 Loss: 13.32972297668457\n",
            "TF: True\n",
            "  Batch: 1790 Loss: 12.820701313018798\n",
            "TF: True\n",
            "  Batch: 1800 Loss: 13.165883255004882\n",
            "TF: True\n",
            "  Batch: 1810 Loss: 13.136349201202393\n",
            "TF: True\n",
            "  Batch: 1820 Loss: 13.058905506134034\n",
            "TF: True\n",
            "  Batch: 1830 Loss: 13.072940063476562\n",
            "TF: False\n",
            "  ,                              -> <START>B                            \n",
            "  near                           -> <START>nanr                         \n",
            "  You                            -> <START>ttu                          \n",
            "  .                              -> <START>.                            \n",
            "  but                            -> <START>Shn                          \n",
            "  Batch: 1840 Loss: 12.737154865264893\n",
            "TF: False\n",
            "  third                          -> <START>rhiet                        \n",
            "  no                             -> <START>sy                           \n",
            "  put                            -> <START>ihn                          \n",
            "  into                           -> <START>hoi                          \n",
            "  his                            -> <START>tth                          \n",
            "  Batch: 1850 Loss: 12.791295051574707\n",
            "TF: False\n",
            "  ,                              -> <START>.                            \n",
            "  former                         -> <START>feepxs                       \n",
            "  far                            -> <START>yoe                          \n",
            "  defence                        -> <START>cipvsn                       \n",
            "  of                             -> <START>tt                           \n",
            "  Batch: 1860 Loss: 13.18611011505127\n",
            "TF: True\n",
            "  Batch: 1870 Loss: 12.315950965881347\n",
            "TF: False\n",
            "  Not                            -> <START>Disn                         \n",
            "  .                              -> <START>,                            \n",
            "  -                              -> <START>o                            \n",
            "  locally                        -> <START>audenoin                     \n",
            "  look                           -> <START>abta                         \n",
            "  Batch: 1880 Loss: 13.4226806640625\n",
            "TF: True\n",
            "  Batch: 1890 Loss: 14.07467565536499\n",
            "TF: False\n",
            "  told                           -> <START>wto                          \n",
            "  and                            -> <START>MJwy                         \n",
            "  ,                              -> <START>,                            \n",
            "  expert                         -> <START>tihot                        \n",
            "  face                           -> <START>wrnnd                        \n",
            "  Batch: 1900 Loss: 12.77689723968506\n",
            "TF: False\n",
            "  speed                          -> <START>eoogh                        \n",
            "  There                          -> <START>dioios1                      \n",
            "  effects                        -> <START>hirtCedt                     \n",
            "  with                           -> <START>prde                         \n",
            "  go                             -> <START>eh                           \n",
            "  Batch: 1910 Loss: 13.1244948387146\n",
            "TF: False\n",
            "  uniform                        -> <START>ohumc                        \n",
            "  ,                              -> <START>t                            \n",
            "  but                            -> <START>virr                         \n",
            "  ,                              -> <START>,                            \n",
            "  grandmother                    -> <START>mgcAuroitg ng                \n",
            "  Batch: 1920 Loss: 12.699610996246339\n",
            "TF: True\n",
            "  Batch: 1930 Loss: 14.048464584350587\n",
            "TF: True\n",
            "  Batch: 1940 Loss: 13.936751556396484\n",
            "TF: False\n",
            "  lead                           -> <START>hoeg                         \n",
            "  Kinnaird                       -> <START>doe-ttd                      \n",
            "  .                              -> <START>,                            \n",
            "  ;                              -> <START>,                            \n",
            "  Arthur                         -> <START>oavfrit                      \n",
            "  Batch: 1950 Loss: 14.482879734039306\n",
            "TF: True\n",
            "  Batch: 1960 Loss: 13.299612522125244\n",
            "TF: True\n",
            "  Batch: 1970 Loss: 13.397077655792236\n",
            "TF: False\n",
            "  because                        -> <START>namt t                       \n",
            "  rollers                        -> <START>trilme n                     \n",
            "  here                           -> <START>gde                          \n",
            "  apply                          -> <START>audne                        \n",
            "  all                            -> <START>hde                          \n",
            "  Batch: 1980 Loss: 12.166819858551026\n",
            "TF: True\n",
            "  Batch: 1990 Loss: 13.938589763641357\n",
            "TF: True\n",
            "  Batch: 2000 Loss: 12.817789363861085\n",
            "TF: True\n",
            "  Batch: 2010 Loss: 12.703160285949707\n",
            "TF: False\n",
            "  young                          -> <START>hhet                         \n",
            "  are                            -> <START>bhn                          \n",
            "  effective                      -> <START>pinusvkh                     \n",
            "  .                              -> <START>,                            \n",
            "  any                            -> <START>blo                          \n",
            "  Batch: 2020 Loss: 13.001096248626709\n",
            "TF: False\n",
            "  whole                          -> <START>dgrt                         \n",
            "  tremble                        -> <START>wphtnte                      \n",
            "  !                              -> <START>.                            \n",
            "  measures                       -> <START>-thntde                      \n",
            "  want                           -> <START>areslr                       \n",
            "  Batch: 2030 Loss: 12.83976345062256\n",
            "TF: True\n",
            "  Batch: 2040 Loss: 13.574435138702393\n",
            "TF: True\n",
            "  Batch: 2050 Loss: 13.506390285491943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-be0b0929d14d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-78-be0b0929d14d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0msymb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_symbol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcurrent_symbol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-d6e32707abae>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, prev, hidden)\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0;31m#print(\"---------------\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#emb = self.embedding(prev)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#print(emb.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-966f37dda9fa>\u001b[0m in \u001b[0;36mto_onehot\u001b[0;34m(x, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Yg8-hpPq2e2p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}