{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTR_tf_unif.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hramchenko/Handwritting/blob/master/HTR_tf_unif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uL5QRz_WMkMF",
        "colab_type": "code",
        "outputId": "48d78bde-6b04-4eb9-ab58-2516173587c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Device \" + torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\")\n",
        "#device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device Tesla K80\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5M_rV-VMqso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVeBVZEgMtb2",
        "colab_type": "code",
        "outputId": "ec09d73b-0fc0-4540-a66d-8df2c75e12f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./Handwritting/\")\n",
        "from IAMWords import IAMWords\n",
        "train_set = IAMWords(\"train\", \"./IAM/\", batch_size=batch_size)\n",
        "test_set = IAMWords(\"test\", \"./IAM/\", batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading ./IAM/words.train.pkl...\n",
            "Reading finished\n",
            "Reading ./IAM/words.test.pkl...\n",
            "Reading finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SiZq2SoAI3yt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def modify_dataset(dataset):\n",
        "  l = len(dataset.codes)\n",
        "  s = \"<START>\"\n",
        "  dataset.codes[s] = l\n",
        "  dataset.inv_codes[l] = s\n",
        "  return dataset\n",
        "\n",
        "train_set = modify_dataset(train_set)\n",
        "test_set = modify_dataset(test_set)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2fWx6tuK-4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLNlm1yURr4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, size, padding=1, pool_layer=nn.MaxPool2d(2, stride=2),\n",
        "                 bn=False, dropout=False, activation_fn=nn.ReLU(), stride=1):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(size[0], size[1], size[2], padding=padding, stride=stride))\n",
        "        if pool_layer is not None:\n",
        "            layers.append(pool_layer)\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(size[1]))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout2d())\n",
        "        layers.append(activation_fn)\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XmHNGG3oRshP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeconvLayer(nn.Module):\n",
        "    def __init__(self, size, padding=1, stride=1, \n",
        "                 bn=False, dropout=False, activation_fn=nn.ReLU(), output_padding=0):\n",
        "        super(DeconvLayer, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.ConvTranspose2d(size[0], size[1], size[2], padding=padding, \n",
        "                                         stride=stride, output_padding=output_padding))\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(size[1]))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout2d())\n",
        "        layers.append(activation_fn)\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hO1gydZeRvE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self, sizes, dropout=False, activation_fn=nn.Tanh):\n",
        "        super(FullyConnected, self).__init__()\n",
        "        layers = []\n",
        "        \n",
        "        for i in range(len(sizes) - 2):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if dropout:\n",
        "                layers.append(nn.Dropout())\n",
        "            layers.append(activation_fn())\n",
        "        else: # нам не нужен дропаут и фнкция активации в последнем слое\n",
        "            layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tNCy7E6BNI1t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = train_set.make_batch()\n",
        "data, target = batch\n",
        "target = target.to(device)\n",
        "data = data/255.0\n",
        "data = data.view(batch_size, 1, 128, 400).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_P9OQHd-uOoE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HTREncoder(nn.Module):\n",
        "    def __init__(self, batchnorm=True, dropout=False):\n",
        "        super(HTREncoder, self).__init__()\n",
        "        \n",
        "        self.convolutions = nn.Sequential(\n",
        "        ConvLayer([1, 16, 3], padding=0, bn=batchnorm),\n",
        "        ConvLayer([16, 32, 3], padding=0, bn=batchnorm),\n",
        "        ConvLayer([32, 50, 3], padding=0, bn=batchnorm),\n",
        "        ConvLayer([50, 64, 3], padding=0, stride=2, bn=batchnorm, pool_layer=None))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.convolutions(x)\n",
        "        h = F.max_pool2d(h, [h.size(2), 1], padding=[0, 0])\n",
        "        h = h.permute([2, 3, 0, 1])[0]\n",
        "        return h\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihilbywpul9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = HTREncoder().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIiy-eFLvC5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HTRDecoder(nn.Module):\n",
        "    def __init__(self, ntoken, encoded_width=23, encoded_height=64, batchnorm=True, dropout=False, rnn_type=\"LSTM\"):\n",
        "        super(HTRDecoder, self).__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.encoded_height = encoded_height\n",
        "        self.lstm_size = 128\n",
        "        lstm_layers = 2\n",
        "        self.rnn_type = rnn_type\n",
        "        if rnn_type == \"LSTM\":\n",
        "          self.rnn = nn.LSTM(self.encoded_height*encoded_width + ntoken, self.lstm_size, lstm_layers, dropout=0.3, bidirectional=True)\n",
        "        else:\n",
        "          self.rnn = nn.GRU(self.encoded_height*encoded_width + ntoken, self.lstm_size, lstm_layers, dropout=0.3, bidirectional=True)\n",
        "        self.embedding = nn.Embedding(ntoken, ntoken)\n",
        "        self.decoder = nn.Linear(1*self.lstm_size*2, ntoken)#*batch_size)\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        self.concatenated = torch.FloatTensor(24, )\n",
        "    \n",
        "    def forward(self, x, prev, hidden=None):\n",
        "        x = self.drop(x)\n",
        "        emb = self.embedding(prev)\n",
        "        emb = emb.permute([1, 0, 2])\n",
        "        x = torch.cat([x, emb], dim=2)\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.drop(x)\n",
        "        x = self.decoder(x)\n",
        "        return x, hidden  \n",
        "      \n",
        "    def makeHidden(self):\n",
        "      if self.rnn_type == \"LSTM\":\n",
        "        h1 = torch.zeros(4, batch_size, self.lstm_size).to(device)\n",
        "        h2 = torch.zeros(4, batch_size, self.lstm_size).to(device)\n",
        "        return (h1, h2)\n",
        "      else:\n",
        "        h1 = torch.zeros(4, batch_size, self.lstm_size).to(device)\n",
        "        return h1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "coyZNSEbv6CS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder = HTRDecoder(len(train_set.codes)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ziLheucQKlpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "START = train_set.codes['<START>']\n",
        "current_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "current_symbol[:, :] = START"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JUtlRV5GxNpu",
        "colab_type": "code",
        "outputId": "f199a683-8c88-4e01-a83c-aa819f4e689d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4278
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "from random import random\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "  print(\"Training epoch \" + str(epoch) + \"...\")\n",
        "  train_set.to_start()\n",
        "  batch_idx = 0\n",
        "  c_loss = 0\n",
        "  START = train_set.codes['<START>']\n",
        "  current_symbol = torch.LongTensor(batch_size, 30+1).to(device)\n",
        "  while True:\n",
        "    batch = train_set.make_batch()\n",
        "    if batch is None:\n",
        "      break\n",
        "    encoder.zero_grad()\n",
        "    decoder.zero_grad()\n",
        "    \n",
        "    data, target = batch\n",
        "    data = data.view(batch_size, 1, 128, 400)/255.0\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    hidden = decoder.makeHidden()    \n",
        "\n",
        "    loss = 0\n",
        "    enc = encoder(data)\n",
        "    #s = enc.contiguous().view(1, batch_size, -1)\n",
        "   \n",
        "    s = enc.permute(1, 0, 2)\n",
        "    s = s.flatten(start_dim=1).view(1, 30, 1472)\n",
        "    \n",
        "    current_symbol[:, 0] = START\n",
        "    use_teacher_forcing = True if random() < teacher_forcing_ratio else False\n",
        "    for i in range(0, target.shape[1]):\n",
        "      symb = current_symbol[:, i].view(batch_size, 1).contiguous()\n",
        "      dec, hidden = decoder(s, symb, hidden)\n",
        "      if use_teacher_forcing:\n",
        "        current_symbol[:, i + 1] = target[:, i]\n",
        "      else:\n",
        "        sampled = torch.multinomial(dec.exp(), 1)\n",
        "        current_symbol[:, i+1] = sampled.squeeze()\n",
        "      o = dec.view(30, 1, 81).flatten(start_dim=0,end_dim=1)\n",
        "      t = target[:, i].flatten()\n",
        "      loss += criterion(o, t)\n",
        "    c_loss += loss.item()\n",
        "    freq = 30\n",
        "    if (batch_idx % freq == 0) and (batch_idx != 0):\n",
        "      print(\"TF: \" + str(use_teacher_forcing))\n",
        "      if not use_teacher_forcing:\n",
        "        for k in range(0, 5):\n",
        "           print(\"  \" + train_set.decode_word(target[k,:]) + \" -> \" + train_set.decode_word(current_symbol[k,:]))\n",
        "      c_loss /= freq \n",
        "      print(\"  Batch: \" + str(batch_idx) + \" Loss: \" + str(c_loss))\n",
        "      c_loss = 0\n",
        "      \n",
        "\n",
        "      \n",
        "    loss.backward()\n",
        "    grad_clip = 0.1\n",
        "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), grad_clip)\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    batch_idx += 1\n",
        "\n",
        "for i in range(0, 100):\n",
        "  train(i)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0...\n",
            "TF: True\n",
            "  Batch: 30 Loss: 78.18799978892008\n",
            "TF: False\n",
            "  of                             -> <START>rN    c       P              \n",
            "  .                              -> <START>H d                          \n",
            "  .                              -> <START>* UG                         \n",
            "  had                            -> <START>  U                      u   \n",
            "  come                           -> <START>;o         l                 \n",
            "  Batch: 60 Loss: 25.050082651774087\n",
            "TF: True\n",
            "  Batch: 90 Loss: 18.67003167470296\n",
            "TF: True\n",
            "  Batch: 120 Loss: 17.281685797373452\n",
            "TF: False\n",
            "  .                              -> <START>toc                          \n",
            "  .                              -> <START>h y                          \n",
            "  shown                          -> <START>Snr g                        \n",
            "  Miss                           -> <START>Wzvekt                       \n",
            "  blind                          -> <START>79eia                        \n",
            "  Batch: 150 Loss: 16.187665780385334\n",
            "TF: False\n",
            "  change                         -> <START>,pqaeai                      \n",
            "  '                              -> <START>                             \n",
            "  ebriety                        -> <START>ahldo   s                    \n",
            "  to                             -> <START>s eo                         \n",
            "  direction                      -> <START>/fey na                      \n",
            "  Batch: 180 Loss: 15.623050435384114\n",
            "TF: True\n",
            "  Batch: 210 Loss: 15.546608543395996\n",
            "TF: True\n",
            "  Batch: 240 Loss: 14.674869696299234\n",
            "TF: False\n",
            "  feelings                       -> <START>hmener                       \n",
            "  the                            -> <START>Kso                          \n",
            "  the                            -> <START>+tg                          \n",
            "  train                          -> <START>avaeod                       \n",
            "  me                             -> <START>:ka                          \n",
            "  Batch: 270 Loss: 14.827863279978434\n",
            "TF: False\n",
            "  EICHMANN                       -> <START>htoeoci                      \n",
            "  once                           -> <START>thrt                         \n",
            "  under                          -> <START>ooke                         \n",
            "  common                         -> <START>tndapssle            d       \n",
            "  .                              -> <START>t                            \n",
            "  Batch: 300 Loss: 14.647011439005533\n",
            "TF: False\n",
            "  faces                          -> <START><START>mss                         \n",
            "  mortgage                       -> <START>acrioeoig                    \n",
            "  .                              -> <START>                             \n",
            "  stomach-ulcers                 -> <START>fisrmridigeOr                \n",
            "  electrically                   -> <START>ttlgein                      \n",
            "  Batch: 330 Loss: 14.91956787109375\n",
            "TF: True\n",
            "  Batch: 360 Loss: 14.247002124786377\n",
            "TF: True\n",
            "  Batch: 390 Loss: 15.089575163523357\n",
            "TF: True\n",
            "  Batch: 420 Loss: 14.206526756286621\n",
            "TF: False\n",
            "  result                         -> <START>taonehn                      \n",
            "  The                            -> <START>ute    s                     \n",
            "  1960                           -> <START>cuu                          \n",
            "  in                             -> <START>ae                           \n",
            "  had                            -> <START>otseu                        \n",
            "  Batch: 450 Loss: 14.399855931599935\n",
            "TF: True\n",
            "  Batch: 480 Loss: 13.909998766581218\n",
            "TF: False\n",
            "  be                             -> <START>f d                          \n",
            "  law                            -> <START>Suhd                         \n",
            "  high                           -> <START>tBwe                         \n",
            "  greater                        -> <START>xttoi r    d                 \n",
            "  for                            -> <START>uey                          \n",
            "  Batch: 510 Loss: 14.11826655069987\n",
            "TF: True\n",
            "  Batch: 540 Loss: 13.626863257090251\n",
            "TF: False\n",
            "  the                            -> <START>te                           \n",
            "  all                            -> <START>tegn                         \n",
            "  room                           -> <START>lmhra                        \n",
            "  a                              -> <START>ti                           \n",
            "  \"                              -> <START>b                            \n",
            "  Batch: 570 Loss: 13.948089408874512\n",
            "TF: False\n",
            "  their                          -> <START>uoree                        \n",
            "  gross                          -> <START>oese                         \n",
            "  them                           -> <START>toee                         \n",
            "  staff                          -> <START>foe l                        \n",
            "  you                            -> <START>osau                         \n",
            "  Batch: 600 Loss: 13.695237350463866\n",
            "TF: False\n",
            "  its                            -> <START>rf                           \n",
            "  month                          -> <START>aa w                         \n",
            "  .                              -> <START>/                            \n",
            "  always                         -> <START>vusom   t                    \n",
            "  I                              -> <START>g                            \n",
            "  Batch: 630 Loss: 13.74581241607666\n",
            "TF: False\n",
            "  new                            -> <START>be                           \n",
            "  summer                         -> <START>phvtei                       \n",
            "  said                           -> <START>hcal                         \n",
            "  be                             -> <START>fo                           \n",
            "  Bryan                          -> <START>hneourd                      \n",
            "  Batch: 660 Loss: 14.13362299601237\n",
            "TF: False\n",
            "  said                           -> <START>an                           \n",
            "  As                             -> <START>ha                           \n",
            "  American                       -> <START> hylucwied                   \n",
            "  blow                           -> <START>aane                         \n",
            "  in                             -> <START>h                            \n",
            "  Batch: 690 Loss: 13.686125405629475\n",
            "TF: True\n",
            "  Batch: 720 Loss: 14.276999155680338\n",
            "TF: False\n",
            "  slightly                       -> <START>tCi lt                       \n",
            "  conference                     -> <START>aeoeyne                      \n",
            "  a                              -> <START>a     t                      \n",
            "  guilds                         -> <START>rtarld                       \n",
            "  !                              -> <START>Q                            \n",
            "  Batch: 750 Loss: 13.725546105702717\n",
            "TF: True\n",
            "  Batch: 780 Loss: 13.788047726949056\n",
            "TF: False\n",
            "  minor                          -> <START>aocnas                       \n",
            "  cosmic                         -> <START>taweoe                       \n",
            "  a                              -> <START>me                           \n",
            "  soon                           -> <START>aif                          \n",
            "  co-operation                   -> <START>5bmerrnnei                   \n",
            "  Batch: 810 Loss: 14.055038992563883\n",
            "TF: True\n",
            "  Batch: 840 Loss: 13.69421453475952\n",
            "TF: False\n",
            "  very                           -> <START>her                          \n",
            "  everyone                       -> <START>aageait                      \n",
            "  ,                              -> <START>.                            \n",
            "  the                            -> <START>wt                           \n",
            "  war                            -> <START>fle                          \n",
            "  Batch: 870 Loss: 14.295118872324625\n",
            "TF: True\n",
            "  Batch: 900 Loss: 13.617712624867757\n",
            "TF: False\n",
            "  the                            -> <START>tr                           \n",
            "  .                              -> <START>m                            \n",
            "  battle                         -> <START>bvanr                        \n",
            "  The                            -> <START>th                           \n",
            "  the                            -> <START>hnhsf                        \n",
            "  Batch: 930 Loss: 13.299035771687825\n",
            "TF: False\n",
            "  \"                              -> <START>.                            \n",
            "  to                             -> <START>ci                           \n",
            "  over                           -> <START>esa                          \n",
            "  throw                          -> <START>dinh                         \n",
            "  what                           -> <START>pdr                          \n",
            "  Batch: 960 Loss: 13.824746990203858\n",
            "TF: True\n",
            "  Batch: 990 Loss: 13.707529671986897\n",
            "TF: True\n",
            "  Batch: 1020 Loss: 13.94697291056315\n",
            "TF: True\n",
            "  Batch: 1050 Loss: 13.918817583719889\n",
            "TF: True\n",
            "  Batch: 1080 Loss: 13.611653264363607\n",
            "TF: False\n",
            "  has                            -> <START>Ran                          \n",
            "  beside                         -> <START>waue                         \n",
            "  of                             -> <START>rt                           \n",
            "  with                           -> <START>Janyn                        \n",
            "  taking                         -> <START>pawrin                       \n",
            "  Batch: 1110 Loss: 13.622924518585204\n",
            "TF: True\n",
            "  Batch: 1140 Loss: 13.381423950195312\n",
            "TF: True\n",
            "  Batch: 1170 Loss: 13.291037400563559\n",
            "TF: False\n",
            "  in                             -> <START>or                           \n",
            "  2a-calling                     -> <START>bcfvnns                      \n",
            "  cannot                         -> <START>Nainrl                       \n",
            "  freedom                        -> <START>aemoand                      \n",
            "  there                          -> <START>_uie                         \n",
            "  Batch: 1200 Loss: 13.867699813842773\n",
            "TF: True\n",
            "  Batch: 1230 Loss: 13.83942543665568\n",
            "TF: True\n",
            "  Batch: 1260 Loss: 13.488271872202555\n",
            "TF: True\n",
            "  Batch: 1290 Loss: 14.26970682144165\n",
            "TF: False\n",
            "  Ponsonby                       -> <START>ajldar                       \n",
            "  families                       -> <START>hmmbi                        \n",
            "  Labour                         -> <START>civuf                        \n",
            "  which                          -> <START>flmuagh                      \n",
            "  very                           -> <START>otgd                         \n",
            "  Batch: 1320 Loss: 13.30116637547811\n",
            "TF: False\n",
            "  had                            -> <START>sst                          \n",
            "  it                             -> <START>Vhe                          \n",
            "  .                              -> <START>.                            \n",
            "  it                             -> <START>bn                           \n",
            "  of                             -> <START>b                            \n",
            "  Batch: 1350 Loss: 13.085094356536866\n",
            "TF: False\n",
            "  ,                              -> <START>.                            \n",
            "  Lord                           -> <START>etat                         \n",
            "  .                              -> <START>.                            \n",
            "  a                              -> <START>                             \n",
            "  the                            -> <START>tO                           \n",
            "  Batch: 1380 Loss: 13.799009418487548\n",
            "TF: True\n",
            "  Batch: 1410 Loss: 13.186045869191487\n",
            "TF: False\n",
            "  (                              -> <START>,                            \n",
            "  day-time                       -> <START>yunlog if                    \n",
            "  is                             -> <START>io                           \n",
            "  negotiations                   -> <START>fhrmaidnui                   \n",
            "  point                          -> <START>cerunil                      \n",
            "  Batch: 1440 Loss: 13.189205106099447\n",
            "TF: True\n",
            "  Batch: 1470 Loss: 13.646103763580323\n",
            "TF: False\n",
            "  \"                              -> <START>o                            \n",
            "  House                          -> <START>aDrr                         \n",
            "  school                         -> <START>oilsg                        \n",
            "  ,                              -> <START>,                            \n",
            "  new                            -> <START>hyo                          \n",
            "  Batch: 1500 Loss: 13.153830210367838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-192-b7bf468b594c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-192-b7bf468b594c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mgrad_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mbatch_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Yg8-hpPq2e2p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}