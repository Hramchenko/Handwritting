{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cleaned_new_proffs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hramchenko/Handwritting/blob/master/cleaned_new_proffs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uL5QRz_WMkMF",
        "colab_type": "code",
        "outputId": "a31284dd-c172-4db1-d783-f6235c1c5264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Device \" + torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\")\n",
        "#device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device Tesla K80\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5M_rV-VMqso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVeBVZEgMtb2",
        "colab_type": "code",
        "outputId": "fa43ead3-0e08-4744-f4e2-752804e120d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./Handwritting/\")\n",
        "from IAMWords import IAMWords\n",
        "image_width = 1500\n",
        "image_height = 200\n",
        "train_set = IAMWords(\"train\", \"./IAM/\", batch_size=batch_size, line_height=image_height, line_width=image_width, scale=1)\n",
        "test_set = IAMWords(\"test\", \"./IAM/\", batch_size=batch_size, line_height=image_height, line_width=image_width, scale=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading ./IAM/words.train.pkl...\n",
            "Reading finished\n",
            "Reading ./IAM/words.test.pkl...\n",
            "Reading finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K2fWx6tuK-4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.core.debugger import set_trace\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLNlm1yURr4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, size, padding=1, pool_layer=nn.MaxPool2d(2, stride=2),\n",
        "                 bn=False, dropout=False, activation_fn=nn.ReLU(), stride=1):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(size[0], size[1], size[2], padding=padding, stride=stride))\n",
        "        if pool_layer is not None:\n",
        "            layers.append(pool_layer)\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(size[1]))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout2d())\n",
        "        layers.append(activation_fn)\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XmHNGG3oRshP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeconvLayer(nn.Module):\n",
        "    def __init__(self, size, padding=1, stride=1, \n",
        "                 bn=False, dropout=False, activation_fn=nn.ReLU(), output_padding=0):\n",
        "        super(DeconvLayer, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.ConvTranspose2d(size[0], size[1], size[2], padding=padding, \n",
        "                                         stride=stride, output_padding=output_padding))\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(size[1]))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout2d())\n",
        "        layers.append(activation_fn)\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hO1gydZeRvE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self, sizes, dropout=False, activation_fn=nn.Tanh):\n",
        "        super(FullyConnected, self).__init__()\n",
        "        layers = []\n",
        "        \n",
        "        for i in range(len(sizes) - 2):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if dropout:\n",
        "                layers.append(nn.Dropout())\n",
        "            layers.append(activation_fn())\n",
        "        else: # нам не нужен дропаут и фнкция активации в последнем слое\n",
        "            layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QuAkNIOOQkar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FullyConnectedX(nn.Module):\n",
        "    def __init__(self, sizes, dropout=False, activation_fn=nn.Tanh(), flatten=False, last_fn=None):\n",
        "        super(FullyConnectedX, self).__init__()\n",
        "        layers = []\n",
        "        self.flatten = flatten\n",
        "        for i in range(len(sizes) - 2):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if dropout:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            layers.append(activation_fn) # нам не нужен дропаут и фнкция активации в последнем слое\n",
        "        else: \n",
        "            layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
        "        if last_fn is not None:\n",
        "            layers.append(last_fn)\n",
        "        self.model = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.flatten:\n",
        "            x = x.view(x.shape[0], -1)\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tNCy7E6BNI1t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = train_set.make_batch(use_binarization=False)\n",
        "data, target = batch\n",
        "target = target.to(device)\n",
        "data = data/255.0\n",
        "data = data.view(batch_size, 1, image_width, image_height).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_P9OQHd-uOoE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HTREncoder(nn.Module):\n",
        "    def __init__(self, batchnorm=False, dropout=False):\n",
        "        super(HTREncoder, self).__init__()\n",
        "        \n",
        "        self.convolutions = nn.Sequential(\n",
        "        ConvLayer([1, 4, 3], padding=0, stride=2, bn=batchnorm, pool_layer=None),\n",
        "        ConvLayer([4, 16, 3], padding=0, stride=2, bn=batchnorm, pool_layer=None),\n",
        "        ConvLayer([16, 32, 3], padding=0, stride=2, bn=batchnorm, pool_layer=None),\n",
        "        ConvLayer([32, 64, 3], padding=0, stride=2, bn=batchnorm, pool_layer=None),\n",
        "        ConvLayer([64, 64, 1], padding=0, stride=(1,11), bn=batchnorm, pool_layer=None))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.convolutions(x)\n",
        "        h = h.squeeze(-1)\n",
        "        return h\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihilbywpul9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = HTREncoder().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3fvJufA-1d9O",
        "colab_type": "code",
        "outputId": "200e9688-b00e-4f92-d16f-8110cb92f5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "c = encoder(data)\n",
        "c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 64, 92])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "cXja4G8p7KKz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_onehot(x, n):\n",
        "    one_hot = torch.zeros((x.shape[0], n)).to(device)\n",
        "    one_hot.scatter_(1, x[:, None], 1.)\n",
        "    if device is not None:\n",
        "        one_hot = one_hot.to(device)\n",
        "    return one_hot  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIiy-eFLvC5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HTRDecoderResult:\n",
        "  \n",
        "  def __init__(self):\n",
        "    None\n",
        "\n",
        "class HTRDecoder(nn.Module):\n",
        "    def __init__(self, ntoken, encoded_width=92, encoded_height=64, batchnorm=False, dropout=True, rnn_type=\"LSTM\"):\n",
        "        super(HTRDecoder, self).__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.encoded_width = encoded_width\n",
        "        self.encoded_height = encoded_height\n",
        "        self.lstm_size = 256\n",
        "        self.lstm_layers = 2\n",
        "        self.rnn_type = rnn_type\n",
        "        self.emb_size = 128\n",
        "        features_size = self.encoded_height*encoded_width + self.emb_size\n",
        "        from math import floor\n",
        "        lstm_inp_size = floor(features_size*0.3)\n",
        "        \n",
        "        if rnn_type == \"LSTM\":\n",
        "          self.rnn = nn.LSTM(lstm_inp_size, self.lstm_size, self.lstm_layers, dropout=0.3, bidirectional=False)\n",
        "        else:\n",
        "          self.rnn = nn.GRU(lstm_inp_size, self.lstm_size, self.lstm_layers, dropout=0.3, bidirectional=False)\n",
        "        self.embedding = nn.Embedding(ntoken, self.emb_size)\n",
        "        self.decoder = nn.Linear(1*self.lstm_size*1, ntoken)#*batch_size)\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc = FullyConnectedX([features_size, floor(features_size*0.7), floor(features_size*0.5), lstm_inp_size], activation_fn=nn.ReLU(), last_fn=nn.Tanh())\n",
        "        \n",
        "        self.attention = FullyConnectedX([self.lstm_size*2 + self.encoded_height*encoded_width, self.encoded_height*encoded_width*2,  self.encoded_width], activation_fn=nn.LeakyReLU(0.2), last_fn=nn.Tanh())\n",
        "        self.attention_weights = None\n",
        "    \n",
        "    def forward(self, x, prev, hidden=None):\n",
        "        x = self.drop(x).squeeze()\n",
        "        if hidden is not None:\n",
        "          hidden_m = hidden.permute(1, 0, 2)\n",
        "          hidden_m = hidden_m.flatten(start_dim=1)\n",
        "          attention_inp = torch.cat([x, hidden_m], dim=1).detach()\n",
        "          self.attention_weights = self.attention(attention_inp)\n",
        "          self.attention_weights = F.softmax(self.attention_weights, dim=1)\n",
        "          self.attention_weights = self.attention_weights.repeat([1, self.encoded_height])\n",
        "          x = x * self.attention_weights\n",
        "        emb = self.embedding(prev).squeeze().detach()\n",
        "        x = torch.cat([x, emb], dim=1)\n",
        "        x = self.fc(x)\n",
        "        x = x.unsqueeze(0)\n",
        "        result = HTRDecoderResult()\n",
        "        result.rnn_input = x\n",
        "        result.input_hidden = hidden\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        x = x.squeeze(dim=0)\n",
        "        x = self.drop(x)\n",
        "        x = self.decoder(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        result.x = x\n",
        "        result.hidden = hidden\n",
        "        return result\n",
        "      \n",
        "    def makeHidden(self):\n",
        "      if self.rnn_type == \"LSTM\":\n",
        "        h1 = torch.zeros(self.lstm_layers, batch_size, self.lstm_size).to(device)\n",
        "        h2 = torch.zeros(self.lstm_layers, batch_size, self.lstm_size).to(device)\n",
        "        return (h1, h2)\n",
        "      else:\n",
        "        h1 = torch.zeros(self.lstm_layers, batch_size, self.lstm_size).to(device)\n",
        "        return h1\n",
        "      \n",
        "decoder = HTRDecoder(len(train_set.codes), rnn_type=\"GRU\").to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ziLheucQKlpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "START = train_set.codes['<START>']\n",
        "current_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "current_symbol[:, :] = START"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHbnIOOP03r-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(max_size=4):\n",
        "  print(\"Testing...\")\n",
        "  \n",
        "  freq = 20\n",
        "  \n",
        "  test_set.to_start(max_size)\n",
        "  batch_idx = 0\n",
        "  c_loss = 0\n",
        "  START = train_set.start_code\n",
        "  STOP = train_set.stop_code\n",
        "  recognition_result = torch.LongTensor(batch_size, 30+1).to(device)\n",
        "  old_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "  \n",
        "  stop_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "  stop_symbol.fill_(STOP)\n",
        "  \n",
        "  test_loss = 0\n",
        "  \n",
        "  with torch.no_grad():  \n",
        "    while True:\n",
        "      batch = test_set.make_batch()\n",
        "      if batch is None:\n",
        "        break\n",
        "\n",
        "      orig_data, target = batch\n",
        "      data = orig_data/255.0\n",
        "      data = data.view(batch_size, 1, image_width, image_height).to(device)\n",
        "      target = target.to(device)\n",
        "      hidden = decoder.makeHidden()    \n",
        "\n",
        "      loss = 0\n",
        "      enc = encoder(data)\n",
        "      s = enc.permute(1, 0, 2)\n",
        "      s = s.flatten(start_dim=1).view(1, batch_size, -1)\n",
        "      old_symbol[:, 0] = START\n",
        "\n",
        "      for i in range(0, target.shape[1]):\n",
        "\n",
        "        decoder_result = decoder(s, old_symbol, hidden)\n",
        "        dec = decoder_result.x\n",
        "        hidden = decoder_result.hidden\n",
        "\n",
        "        recognition_result[:, i] = dec.topk(1, dim=1)[1].flatten().detach()\n",
        "        old_symbol[:, 0] = target[:, i]\n",
        "\n",
        "        loss += criterion(dec, target[:, i])\n",
        "      c_loss += loss.item()/(target.shape[1] + 0)\n",
        "      test_loss += loss.item()/(target.shape[1] + 0)\n",
        "      if (batch_idx % freq == 0) and (batch_idx != 0):\n",
        "        if True:#not use_teacher_forcing:\n",
        "          for k in range(0, min(3, target.shape[0])):\n",
        "              decoded = recognition_result[k,0:target.shape[1]]\n",
        "              plt.imshow(orig_data[k].cpu(), cmap=\"gray\")\n",
        "              plt.show()\n",
        "              print(\"  \" + train_set.decode_word(target[k,:]) + \" -> \" + train_set.decode_word(decoded))\n",
        "        c_loss /= freq \n",
        "        print(\"  Batch: \" + str(batch_idx) + \" Loss: \" + str(c_loss))\n",
        "        c_loss = 0\n",
        "      batch_idx += 1  \n",
        "  print(\"Test loss: %f\" % (test_loss/batch_idx))   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1dvEYjtLYlcN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Based on https://github.com/aryopg/Professor_Forcing_Pytorch/blob/master/models/losses.py\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, input_length, symbs_cnt):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(symbs_cnt, 128)\n",
        "        \n",
        "        from math import floor\n",
        "        self.hidden_cells = 256\n",
        "        self.hidden_layers = 2\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_length = input_length\n",
        "        self.rnn_layers = 2\n",
        "        \n",
        "        input_size = 512 + 1804 + 128\n",
        "        gru_input_size = 256*2\n",
        "        \n",
        "        self.enc = FullyConnectedX([input_size, floor(input_size*0.7), gru_input_size], activation_fn=nn.ReLU())\n",
        "\n",
        "        self.gru = nn.GRU(gru_input_size, hidden_size, self.rnn_layers)\n",
        "        \n",
        "        gru_out = hidden_size\n",
        "        self.fc = FullyConnectedX([gru_out, floor(gru_out*0.7), floor(gru_out*0.3), 1], activation_fn=nn.ReLU())\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "        \n",
        "    def zero_grad(self):\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "    def apply(self, hidden, hidden_states, dec_inputs, dec_outputs, targets):\n",
        "        emb_outputs = self.embedding(dec_outputs)#.permute(1, 0, 2)\n",
        "        hidden_states = hidden_states.permute(1, 0, 2).flatten(start_dim=1)\n",
        "        dec_inputs = dec_inputs.squeeze(0)\n",
        "        full_input = torch.cat([hidden_states, dec_inputs, emb_outputs], dim=1)\n",
        "        output = self.enc(full_input)\n",
        "        output = output.unsqueeze(0)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output= output.squeeze(0)\n",
        "        out = self.fc(output)\n",
        "        loss = F.binary_cross_entropy_with_logits(out, targets)\n",
        "        return loss, hidden\n",
        "\n",
        "    def makeHidden(self):\n",
        "        return torch.zeros(self.rnn_layers, batch_size, self.hidden_size, device=device)\n",
        "      \n",
        "discriminator = Discriminator(256*2, 512, 10, len(train_set.codes)).to(device)      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zel5bfutWKKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def apply_discriminator(s, target, use_teacher_forcing, train_mode, discriminator_target):\n",
        "  loss = 0\n",
        "  START = train_set.start_code\n",
        "  STOP = train_set.stop_code\n",
        "  recognition_result = torch.LongTensor(batch_size, 30+1).to(device)\n",
        "  old_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "  stop_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "  stop_symbol.fill_(STOP)\n",
        "  old_symbol[:, 0] = START\n",
        "\n",
        "  hidden = decoder.makeHidden()    \n",
        "  discriminator_loss = 0\n",
        "  discriminator_hidden = discriminator.makeHidden()\n",
        "\n",
        "  for i in range(0, target.shape[1]):\n",
        "\n",
        "    decoder_result = decoder(s, old_symbol, hidden)\n",
        "    dec = decoder_result.x\n",
        "    hidden = decoder_result.hidden\n",
        "\n",
        "    decoder_outputs = dec.topk(1, dim=1)[1].flatten()\n",
        "    \n",
        "    if train_mode:\n",
        "      dl, discriminator_hidden = discriminator.apply(discriminator_hidden.detach(), decoder_result.input_hidden.detach(),decoder_result.rnn_input.detach(), decoder_outputs.detach(), discriminator_target)\n",
        "    else:\n",
        "      dl, discriminator_hidden = discriminator.apply(discriminator_hidden, decoder_result.input_hidden, decoder_result.rnn_input, decoder_outputs, discriminator_target)\n",
        "      \n",
        "    if i != 0:\n",
        "      discriminator_loss += dl\n",
        "\n",
        "    recognition_result[:, i] = decoder_outputs.detach()\n",
        "    if use_teacher_forcing:\n",
        "      old_symbol[:, 0] = target[:, i]\n",
        "    else:\n",
        "      old_symbol[:, 0] = recognition_result[:, i]\n",
        "\n",
        "    loss += criterion(dec, target[:, i])\n",
        "  if target.shape[1] > 1:\n",
        "    discriminator_loss /= target.shape[1] - 1\n",
        "  return (recognition_result, loss, discriminator_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yrtvy2ikWNwI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def apply_decoder(s, target, use_teacher_forcing):\n",
        "  loss = 0\n",
        "  START = train_set.start_code\n",
        "  STOP = train_set.stop_code\n",
        "  recognition_result = torch.LongTensor(batch_size, 30+1).to(device)\n",
        "  old_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "  stop_symbol = torch.LongTensor(batch_size, 1).to(device)\n",
        "  stop_symbol.fill_(STOP)\n",
        "  old_symbol[:, 0] = START\n",
        "\n",
        "  hidden = decoder.makeHidden()    \n",
        "\n",
        "  for i in range(0, target.shape[1]):\n",
        "\n",
        "    decoder_result = decoder(s, old_symbol, hidden)\n",
        "    dec = decoder_result.x\n",
        "    hidden = decoder_result.hidden\n",
        "\n",
        "    recognition_result[:, i] = dec.topk(1, dim=1)[1].flatten().detach()\n",
        "    if use_teacher_forcing:\n",
        "      old_symbol[:, 0] = target[:, i]\n",
        "    else:\n",
        "      old_symbol[:, 0] = recognition_result[:, i]\n",
        "    #import pdb; pdb.set_trace()\n",
        "\n",
        "    loss += criterion(dec, target[:, i])\n",
        "  return (recognition_result, loss)\n",
        "\n",
        "\n",
        "batch_zeros = torch.zeros(batch_size, 1).to(device)\n",
        "batch_ones = torch.ones(batch_size, 1).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1DxYdkXeTnNB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4, weight_decay=0.00005)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "teacher_forcing_ratio = 1#0.5\n",
        "\n",
        "from random import random\n",
        "\n",
        "def train(epoch, max_size):\n",
        "  print(\"Training epoch \" + str(epoch) + \"...\")\n",
        "  \n",
        "  freq = 30\n",
        "  \n",
        "  train_set.to_start(max_size)\n",
        "  batch_idx = 0\n",
        "  c_loss = 0\n",
        "  \n",
        "  train_loss = 0\n",
        "  \n",
        "  while True:\n",
        "    batch = train_set.make_batch()\n",
        "    if batch is None:\n",
        "      break\n",
        "    \n",
        "    orig_data, target = batch\n",
        "    data = orig_data/255.0\n",
        "    data = data.view(batch_size, 1, image_width, image_height).to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    encoder.zero_grad()\n",
        "    decoder.zero_grad()\n",
        "    \n",
        "    enc = encoder(data)\n",
        "    s = enc.permute(1, 0, 2)\n",
        "    s = s.flatten(start_dim=1).view(1, batch_size, -1)\n",
        "    \n",
        "    discr_loss = 1\n",
        "    if target.shape[1] > 1:\n",
        "      discriminator_optimizer.zero_grad()\n",
        "      _, _, tf_loss = apply_discriminator(s, target, True, True, batch_ones)\n",
        "      _, _, fr_loss = apply_discriminator(s, target, False, True, batch_zeros)\n",
        "      dl = tf_loss + fr_loss\n",
        "      discr_loss = dl.item()\n",
        "      if (batch_idx % freq == 0) and (batch_idx != 0):\n",
        "        print(\"Discr loss: %f\" %(dl.item()))\n",
        "      dl.backward()\n",
        "      discriminator_optimizer.step()\n",
        "   \n",
        "    batch_loss = None  \n",
        "    if (target.shape[1] > 1) and (discr_loss < 0.3):\n",
        "      discriminator_optimizer.zero_grad()\n",
        "      recognition_result, loss, discriminator_loss = apply_discriminator(s, target, True, False, batch_zeros)\n",
        "      batch_loss = loss.item()\n",
        "      loss = loss + discriminator_loss\n",
        "      print(\"Apply descr...\")\n",
        "    else:\n",
        "      recognition_result, loss = apply_decoder(s, target, True)\n",
        "      batch_loss = loss.item()\n",
        "      \n",
        "    c_loss += batch_loss/(target.shape[1] + 0)\n",
        "    train_loss += batch_loss/(target.shape[1] + 0)\n",
        "    if (batch_idx % freq == 0) and (batch_idx != 0):\n",
        "      \n",
        "      if False:#True:#not use_teacher_forcing:\n",
        "        for k in range(0, min(3, target.shape[0])):\n",
        "            decoded = recognition_result[k,0:target.shape[1]]\n",
        "            plt.imshow(orig_data[k].cpu(), cmap=\"gray\")\n",
        "            plt.show()\n",
        "            print(\"  \" + train_set.decode_word(target[k,:]) + \" -> \" + train_set.decode_word(decoded))\n",
        "      c_loss /= freq \n",
        "      print(\"  Batch: \" + str(batch_idx) + \" Loss: \" + str(c_loss))\n",
        "      c_loss = 0\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    batch_idx += 1\n",
        "  print(\"Train loss: %f\"%(train_loss/batch_idx))\n",
        "\n",
        "for i in range(0, 100):\n",
        "  max_size = 5\n",
        "  train(i, max_size)\n",
        "  test(max_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fx-SPJM4Iz5t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Batch: 20 Loss: 1.883674645423889\n",
        "Test loss: 1.761937\n",
        "Training epoch 15...\n",
        "Discr loss: 0.362759\n",
        "  Batch: 30 Loss: 1.8283645841810439\n",
        "Discr loss: 0.745832\n",
        "  Batch: 60 Loss: 1.7917157755957709\n",
        "Apply descr...\n",
        "Discr loss: 0.704203\n",
        "  Batch: 90 Loss: 1.8291594637764823\n",
        "Discr loss: 0.630240\n",
        "  Batch: 120 Loss: 1.7885543584823609\n",
        "Discr loss: 0.554544\n",
        "  Batch: 150 Loss: 1.9939753095308939\n",
        "Discr loss: 0.834231\n",
        "  Batch: 180 Loss: 1.771349260542128\n",
        "Discr loss: 0.375062\n",
        "  Batch: 210 Loss: 1.7672387520472208\n",
        "Apply descr...\n",
        "Apply descr...\n",
        "Discr loss: 0.358869\n",
        "  Batch: 240 Loss: 1.8861849890814886\n",
        "Discr loss: 0.493518\n",
        "  Batch: 270 Loss: 1.8778088357713487\n",
        "Discr loss: 0.381331\n",
        "  Batch: 300 Loss: 1.786535980966356\n",
        "  Batch: 330 Loss: 1.7695309612486099\n",
        "Discr loss: 0.765729\n",
        "  Batch: 360 Loss: 1.8182820253902012\n",
        "Train loss: 1.810242\n",
        "Testing...\n",
        "\n",
        "  that -> thet\n",
        "\n",
        "  good -> totd\n",
        "\n",
        "  ever -> taer\n",
        "  Batch: 20 Loss: 1.8635647694269817\n",
        "Test loss: 1.773872\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}