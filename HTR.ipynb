{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hramchenko/Handwritting/blob/master/HTR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "B2SyXNlg2yfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fbb732c-774d-4de5-9a0f-6d7e59d3cac8"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Device \" + torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\")\n",
        "#device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device Tesla K80\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zy6PDe1WfYVc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKxS6mCu4TPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "27106230-76c7-404f-ad6b-00eb84c5466f"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./Handwritting/\")\n",
        "from IAMWords import IAMWords\n",
        "train = IAMWords(\"train\", \"./IAM/\", batch_size=batch_size)\n",
        "test = IAMWords(\"test\", \"./IAM/\", batch_size=batch_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading ./IAM/words.train.pkl...\n",
            "Reading finished\n",
            "Reading ./IAM/words.test.pkl...\n",
            "Reading finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CgHMSnzu27x3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class HTRNet(nn.Module):\n",
        "    def __init__(self, cnn_cfg, rnn_cfg, nclasses):\n",
        "        super(HTRNet, self).__init__()\n",
        "\n",
        "        #cfg = [(2, 16), 'M', (4, 32), 'M', (6, 64), 'M', (2, 128)]\n",
        "\n",
        "        in_channels = 1\n",
        "        self.features = nn.ModuleList([])\n",
        "        cntm = 0\n",
        "        cnt = 1\n",
        "        for m in cnn_cfg:\n",
        "            if m == 'M':\n",
        "                self.features.add_module('mxp' + str(cntm), nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "                cntm += 1\n",
        "            else:\n",
        "                for i in range(m[0]):\n",
        "                    x = m[1]\n",
        "                    self.features.add_module('cnv' + str(cnt), nn.Conv2d(in_channels, x, 3, 1, 1, bias=True))\n",
        "                    #self.features.add_module('cnv' + str(cnt), BasicBlock(in_channels, x))\n",
        "                    in_channels = x\n",
        "                    self.features.add_module('nl' + str(cnt), nn.Sequential(nn.BatchNorm2d(x, momentum=.5), nn.ReLU()))\n",
        "                    #self.features.add_module('nl' + str(cnt), nn.ReLU())\n",
        "                    cnt += 1\n",
        "\n",
        "\n",
        "        rnn_in = cnn_cfg[-1][-1]\n",
        "        hidden, num_layers = rnn_cfg\n",
        "\n",
        "        self.rec = nn.LSTM(rnn_in, hidden, num_layers=num_layers, bidirectional=True)\n",
        "\n",
        "        self.fnl = nn.Sequential(nn.Linear(2*hidden, 400), nn.ReLU(), nn.Dropout(.5), nn.Linear(400, nclasses))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = x\n",
        "        for nn_module in self.features:\n",
        "            y = nn_module(y)\n",
        "\n",
        "        y = F.max_pool2d(y, [y.size(2), 1], padding=[0, 0])\n",
        "        y = y.permute(2, 3, 0, 1)[0]  # 1 x seq_len x batch_size x feat\n",
        "        y = self.rec(y)[0] #.view(1, -1)\n",
        "        y = self.fnl(y)\n",
        "\n",
        "        return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XBNTbPaO3hNS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_cfg = [(2, 32), 'M', (4, 64), 'M', (6, 128), 'M', (2, 256)]\n",
        "rnn_cfg = (256, 1)  # (hidden , num_layers)\n",
        "net = HTRNet(cnn_cfg, rnn_cfg, len(train.alphabet)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9m8QB5UdHH1L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from warpctc_pytorch import CTCLoss\n",
        "loss = CTCLoss()\n",
        "net_parameters = net.parameters()\n",
        "nlr = 1e-4\n",
        "optimizer = torch.optim.Adam(net_parameters, nlr, weight_decay=0.00005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjVsv0vTjACC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data, target = train.make_batch()\n",
        "data = data.view(batch_size, 1, 128, 400)\n",
        "data = data.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Rnh2zVSjID2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = net(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQYzHSsyjYtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e4bc14e-018f-425f-d5c6-9674280c7a98"
      },
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 10, 80])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "XpUikcx2ji15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b3ea6eb-2be1-4e3a-9cde-6a11f8d99915"
      },
      "cell_type": "code",
      "source": [
        "len(test.alphabet)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "zbhYAGlukitZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    # acts: Tensor of (seqLength x batch x outputDim) containing output activations from network (before softmax)\n",
        "    # labels: 1 dimensional Tensor containing all the targets of the batch in one large sequence\n",
        "    # act_lens: Tensor of size (batch) containing size of each output sequence from the network\n",
        "    # label_lens: Tensor of (batch) containing label length of each example"
      ]
    },
    {
      "metadata": {
        "id": "_-JLmpLGkaMA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "act_lens = torch.IntTensor(img.size(0)*[output.size(0)])\n",
        "labels = Variable(torch.IntTensor([cdict[c] for c in ''.join(transcr)]))\n",
        "label_lens = torch.IntTensor([len(t) for t in transcr])\n",
        "\n",
        "loss_val = loss(output.cpu(), labels, act_lens, label_lens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TORm9jnSkwJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f52c9a2e-ca7c-4016-8669-da8477586dd7"
      },
      "cell_type": "code",
      "source": [
        "o = output#.permute(1, 0, 2)\n",
        "o.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 10, 80])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "h_X45RKCk7oV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4315753e-219f-4d78-bb4c-b663ba73ed87"
      },
      "cell_type": "code",
      "source": [
        "t = target.flatten()\n",
        "t.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "55jCFZcLlOwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "563463fc-aaca-4434-ec3d-515ae6009db9"
      },
      "cell_type": "code",
      "source": [
        "al = torch.IntTensor(batch_size*[o.shape[0]])\n",
        "al "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([50, 50, 50, 50, 50, 50, 50, 50, 50, 50], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "SzClBFOMl8rj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f30dea59-d844-4e92-e970-a8bac884190a"
      },
      "cell_type": "code",
      "source": [
        "ll = torch.IntTensor(batch_size*[target.shape[1]])\n",
        "ll"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([30, 30, 30, 30, 30, 30, 30, 30, 30, 30], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "0TeWJhEumK55",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c4388ec-de8b-4061-e1f5-4ede05978177"
      },
      "cell_type": "code",
      "source": [
        "lss = loss(output, target.flatten(), al, ll)\n",
        "lss"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2036.5027], grad_fn=<_CTCBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "C3gbEJgunlLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1474
        },
        "outputId": "d8c07059-4565-4e5b-ad10-5f2ec60c98bc"
      },
      "cell_type": "code",
      "source": [
        "output"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-9.2984e-02,  2.6708e-02,  1.6410e-01,  ...,  1.6956e-02,\n",
              "           5.7450e-02,  5.7150e-02],\n",
              "         [ 2.1227e-02,  1.3474e-01,  2.2912e-01,  ...,  8.8107e-02,\n",
              "           7.1193e-02, -7.4169e-02],\n",
              "         [ 9.0972e-02,  8.3708e-02,  1.6955e-01,  ...,  5.8192e-02,\n",
              "           1.6916e-01, -6.9750e-03],\n",
              "         ...,\n",
              "         [ 1.9357e-02,  6.4526e-02,  2.3440e-01,  ..., -2.2923e-02,\n",
              "           5.7868e-02,  9.0086e-03],\n",
              "         [-4.8007e-02,  6.1810e-02,  2.5245e-01,  ...,  3.5174e-02,\n",
              "           1.3194e-01, -2.8149e-02],\n",
              "         [ 1.9059e-03,  5.8252e-02,  8.1492e-02,  ..., -7.4695e-03,\n",
              "           1.2975e-01, -2.8046e-02]],\n",
              "\n",
              "        [[-2.3815e-02,  7.2186e-02,  1.4510e-01,  ..., -4.8895e-02,\n",
              "           6.1914e-02,  4.6696e-02],\n",
              "         [-1.1655e-01, -5.6488e-02,  1.1558e-01,  ...,  9.0759e-02,\n",
              "           1.7135e-01, -7.0518e-03],\n",
              "         [ 6.0257e-02,  7.9678e-02,  2.5769e-01,  ...,  7.5825e-02,\n",
              "           1.0033e-01, -6.1019e-02],\n",
              "         ...,\n",
              "         [-3.2652e-02,  1.1423e-01,  1.4958e-01,  ...,  7.2395e-03,\n",
              "          -5.8529e-02, -1.7484e-01],\n",
              "         [-5.3163e-02, -5.1568e-02,  1.6726e-01,  ...,  1.3148e-02,\n",
              "           5.7315e-02,  7.6046e-02],\n",
              "         [-2.9124e-02,  3.2656e-02,  2.6538e-01,  ...,  4.4483e-02,\n",
              "           1.4387e-01, -1.1971e-01]],\n",
              "\n",
              "        [[-1.1567e-02, -1.4795e-02,  1.6982e-01,  ..., -5.6838e-02,\n",
              "           1.8413e-01,  9.0565e-02],\n",
              "         [ 6.2388e-02, -2.7732e-03,  1.3146e-01,  ...,  1.2131e-01,\n",
              "           3.4742e-02,  1.3066e-01],\n",
              "         [-4.9999e-02, -4.6903e-02,  1.6369e-01,  ..., -9.8411e-02,\n",
              "           1.8111e-02,  3.7165e-02],\n",
              "         ...,\n",
              "         [-6.2554e-02,  4.2990e-02,  2.8393e-01,  ...,  1.9186e-02,\n",
              "           7.3985e-02,  7.3660e-02],\n",
              "         [ 5.5211e-02,  3.7536e-02,  9.3560e-02,  ..., -7.2990e-03,\n",
              "           1.5532e-03,  6.4891e-03],\n",
              "         [ 4.0249e-02, -4.1152e-02,  9.6745e-02,  ..., -2.9263e-02,\n",
              "           1.5554e-01,  1.4645e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-2.3775e-02,  2.0136e-02,  3.8311e-02,  ...,  2.3854e-02,\n",
              "           4.4285e-02, -6.5150e-02],\n",
              "         [-3.4962e-02,  3.1932e-02,  1.0565e-01,  ...,  2.1064e-02,\n",
              "           4.9055e-02, -3.6477e-04],\n",
              "         [ 4.4940e-02,  9.5167e-02,  3.0344e-03,  ...,  5.7908e-02,\n",
              "           7.9833e-02, -1.7513e-02],\n",
              "         ...,\n",
              "         [-5.5669e-02,  2.7149e-02,  4.9671e-02,  ...,  7.5622e-03,\n",
              "           3.5770e-02, -5.6591e-02],\n",
              "         [ 1.1481e-02,  4.8310e-02,  4.5221e-02,  ..., -3.0898e-02,\n",
              "          -2.8576e-03,  4.1608e-03],\n",
              "         [-1.4344e-04,  4.6331e-02,  1.1137e-01,  ..., -1.9369e-02,\n",
              "           3.4219e-02, -3.5470e-02]],\n",
              "\n",
              "        [[-4.6047e-02,  3.9724e-02,  9.1045e-02,  ..., -4.9387e-03,\n",
              "           3.0871e-02, -1.9439e-02],\n",
              "         [-6.9761e-03,  7.4135e-02,  9.4460e-02,  ...,  1.7356e-02,\n",
              "           7.9246e-02, -3.5530e-02],\n",
              "         [-1.5506e-02,  5.2863e-02,  7.7907e-02,  ...,  5.4892e-02,\n",
              "           3.6722e-02, -2.6123e-03],\n",
              "         ...,\n",
              "         [ 1.2767e-02,  1.5702e-03,  7.4420e-02,  ...,  3.6087e-02,\n",
              "           2.8678e-02, -1.5055e-02],\n",
              "         [-1.4025e-02,  4.4475e-02,  5.6514e-02,  ...,  4.0204e-02,\n",
              "           4.9340e-02, -2.3937e-02],\n",
              "         [-2.8494e-02,  1.5719e-02,  8.6887e-02,  ...,  1.6182e-02,\n",
              "           2.9613e-02,  1.4482e-02]],\n",
              "\n",
              "        [[ 5.3869e-03,  7.2258e-02,  1.2022e-01,  ...,  1.2557e-02,\n",
              "          -4.7685e-03,  1.8669e-02],\n",
              "         [-1.3085e-02,  8.9515e-04,  1.5277e-01,  ..., -8.3655e-03,\n",
              "           4.9503e-02, -3.9400e-03],\n",
              "         [ 4.2620e-03,  6.3934e-02,  6.6003e-02,  ...,  1.6902e-02,\n",
              "           2.4803e-02,  3.7207e-02],\n",
              "         ...,\n",
              "         [-3.1952e-02,  6.1317e-02,  1.3445e-01,  ...,  6.8110e-02,\n",
              "          -7.7587e-03,  2.2310e-03],\n",
              "         [-8.0434e-03,  6.0567e-02,  1.0529e-01,  ...,  2.4206e-02,\n",
              "           1.4907e-02, -1.0105e-02],\n",
              "         [-9.8760e-03,  2.5017e-02,  6.0211e-02,  ...,  6.0091e-02,\n",
              "           1.3967e-02,  9.7879e-03]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "R0rgBUIZmVO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "973f89da-3e90-4c42-d31a-14de5c0a0cf4"
      },
      "cell_type": "code",
      "source": [
        "lss"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<_CTCBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "JTOg8oLtmbK6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tcWDgajpmd6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c467145-669b-4112-f49d-a9f6200d1a1a"
      },
      "cell_type": "code",
      "source": [
        "lss"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<_CTCBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "jcLbgtZFJkN7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import ctcdecode\n",
        "decoder = ctcdecode.CTCBeamDecoder([c for c in test.alphabet], beam_width=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zSkFsk6VfUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1487
        },
        "outputId": "6a7a2926-2f10-4ea3-cff3-c7427fc2a9f1"
      },
      "cell_type": "code",
      "source": [
        "batch_idx = 0\n",
        "train.to_start()\n",
        "al = torch.IntTensor(batch_size*[o.shape[0]])\n",
        "ll = torch.IntTensor(batch_size*[target.shape[1]])\n",
        "while True:\n",
        "  batch = train.make_batch()\n",
        "  \n",
        "  if batch is None:\n",
        "    break\n",
        "  data, target = batch\n",
        "  data = data.view(batch_size, 1, 128, 400)\n",
        "  data = data.to(device)\n",
        "  print(data.shape)\n",
        "  output = net.forward(data)\n",
        "  \n",
        "  loss_val = loss(output, target.flatten(), al, ll)\n",
        "  print(loss_val)\n",
        "  \n",
        "#   act_lens = torch.IntTensor(128*[output.size(0)])\n",
        "#   #labels = Variable(torch.IntTensor([cdict[c] for c in ''.join(transcr)]))\n",
        "#   label_lens = torch.IntTensor([len(t) for t in transcr])\n",
        "\n",
        "#   loss_val = loss(output, labels, act_lens, label_lens)\n",
        "#   #closs += [loss_val.data]\n",
        "\n",
        "#   loss_val.backward()\n",
        "\n",
        "  \n",
        "  batch_idx += 1\n",
        "  if (batch_idx % 10 == 0):\n",
        "    print(batch_idx)\n",
        "  "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2039.3319], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.7579], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.5931], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2037.3873], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.4689], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2036.3082], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2036.7057], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.3156], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.1860], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2039.3909], grad_fn=<_CTCBackward>)\n",
            "10\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.5283], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2037.3938], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2036.8712], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2037.9092], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2037.9294], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2036.8707], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2037.1860], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2040.9192], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.9246], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2037.1509], grad_fn=<_CTCBackward>)\n",
            "20\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2037.1667], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.2605], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2036.2002], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2039.7463], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n",
            "tensor([2038.9490], grad_fn=<_CTCBackward>)\n",
            "torch.Size([10, 1, 128, 400])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-31f530d4e1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/warpctc_pytorch-0.1-py3.6-linux-x86_64.egg/warpctc_pytorch/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, acts, labels, act_lens, label_lens)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         return self.ctc(acts, labels, act_lens, label_lens, self.size_average,\n\u001b[0;32m---> 82\u001b[0;31m                         self.length_average, self.blank)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/warpctc_pytorch-0.1-py3.6-linux-x86_64.egg/warpctc_pytorch/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, acts, labels, act_lens, label_lens, size_average, length_average, blank)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0macts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_ctc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ctc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mwarp_ctc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_ctc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mminibatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9t0iU5ooYeSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "43f6f780-299f-4489-bd58-11a653eb2b0d"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from warpctc_pytorch import CTCLoss\n",
        "ctc_loss = CTCLoss()\n",
        "# expected shape of seqLength x batchSize x alphabet_size\n",
        "probs = torch.FloatTensor([[[0.1, 0.6, 0.1, 0.1, 0.1], [0.1, 0.1, 0.6, 0.1, 0.1]]]).transpose(0, 1).contiguous()\n",
        "print(probs.shape)\n",
        "labels = torch.IntTensor([1, 2])\n",
        "label_sizes = torch.IntTensor([2])\n",
        "probs_sizes = torch.IntTensor([2])\n",
        "probs.requires_grad_(True)  # tells autograd to compute gradients for probs\n",
        "cost = ctc_loss(probs, labels, probs_sizes, label_sizes)\n",
        "print(cost)\n",
        "cost.backward()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 5])\n",
            "tensor([2.4629], grad_fn=<_CTCBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tXm_GJUznCH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}